# 1-1. 자료구조

+ Array and List
+ LinkedList
+ Stack and Queue
+ Priority Queue
+ Graph
+ Tree
+ Binary Tree
+ heap
+ Hash

</br>

## 자료구조의 필요성

    전산학에서 자료를 효율적으로 이용할 수 있도록 컴퓨터에 저장하는 방법이다. 
    신중히 선택한 자료구조는 보다 효율적인 알고리즘을 사용할 수 있게 한다. 
    이러한 자료구조의 선택문제는 대개 추상적 자료구조의 선택으로부터 시작하는 경우가 많다. 
    효과적으로 설계된 자료구조는 실행시간 혹은 메모리 용량 등의 자원을 최소한으로 사용하면서 연산을 수행하도록 한다. 
    - 위키백과 -

즉, 제한된 컴퓨터 자원에서 최대한의 효율을 뽑기 위해서 만들어진 선조들의 노오력의 산물이라는 것이다.   
cpu와 메모리가 끔찍할 정도로 강력해진 현재에 와서는 그 필요성이 상대적으로 줄어들었지만 여전히 컴퓨터에서 너무나도 중요한 내용이다.   
같은 문제를 풀어도 자료구조를 아는 사람이 모르는 사람보다 더 짧은 코딩으로 더 빠른 알고리즘을 만드는 경우가 많으며 아무리 cpu와 메모리가 강력해진다 하더라도 그 만큼 사람들이 더 어려운 문제를(대표적으로 빅데이터, AI) 컴퓨터를 활용하여 처리하기 때문이다.

Array와 List, 일부에서는 Queue 등.. 자료형처럼 사용하지만 엄밀하게 **자료구조**이고 개발자의 편의를 위해서 자주 사용하는 자료구조를 자료형으로 만들어 라이브러리로 제공하는 것으로 최적화를 진행해야할 시 어떻게 코드가 짜여있는지 아는 것이 중요하다.   

자료구조는 기본적인 자료형(Int, Boolean, String 등)을 어떻게 관리할지, 이름 그대로 자료의 구조를 고안한 것으로 데이터의 추가, 삭제, 정렬 등의 시간복잡도(Big-O)를 파악하는 것이 중요하다.

**<code>꼭 자료구조 종류의 특징과 유사한 자료구조 간의 차이점을 중심으로 읽고 다른 카테고리(DB, 네트워크 등)의 기본이 됨을 기억하자!</code>**

해당 글은 다양한 블로그와 <https://www.codeground.org>의 Codeground Note, 영문위키를 참고하여 작성하였음을 밝힌다.   
또한, 백준 문제 풀이는 모두 Kotlin으로 해결하였으며 깃허브에는 풀이 방법과 과정에 대한 설명을 작성하였다. (너무 간단해서 작성할 내용이 없다면 설명이 없을 수도 있다)

</br>

## Array and List

### Array (배열)

가장 기초적인 선형 자료구조이다. 

#### 용어

1. Index(인덱스) : 배열에 순차적으로 저장한 값의 위치를 의미

#### 설명

Index를 이용하여 랜덤 접근(random access)이 가능한 순차적 자료구조이다.

#### 특징

1. 논리적 저장 순서와 물리적 저장 순서가 일치한다.
2. 위의 이유로 index를 사용하여 O(1)에 원하는 원소로 접근이 가능하다.   
   random access가 가능하다고 한다.
5. 원소의 갯수는 초기화를 진행할 당시의 크기로 고정된다.
3. 값을 삭제하면 배열의 크기가 줄어들지 않고 단순히 빈 공간이 돤다.
4. 위의 이유로 메모리가 낭비된다.

#### 예시

순서대로 10, 20, 30, 40, 50을 Array에 넣은 후 40을 삭제하면   
10, 20, 30,  , 50이 된다. 40이 담겨있던 곳은 비어있게 된고 메모리 낭비가 일어난다.

</br>

### List (리스트)

빈 공간 만들지 않는 선형 자료구조이다.   
일반적으로는 배열을 활용하여 구현(dynamic arrays 동적배열)하지만 노드와 링크를 활용하여 구현(LinkedList)하기도 한다.   
노드와 링크를 활용하여 구현하는 방법은 [아래에 서술](https://github.com/ii200400/IT_Skill_Question/tree/master/CS/DataStructure#linkedlist-%EC%97%B0%EA%B2%B0%EB%A6%AC%EC%8A%A4%ED%8A%B8)하므로 지금은 배열을 활용하여 구현하였을 경우의 특징을 정리하겠다.

참고로 리스트는 언어별로 자료형의 이름이 비슷하면서도 작동 방식은 상이할 수 있으므로 언어에서 리스트가 어떻게 작동되는지 잘 파악하기를 바란다. 이러한 점 때문에 필자는 각자 상이한 블로그 글로 인해서 크게 혼란스러웠다.

#### 설명

Index를 이용하여 랜덤 접근(random access)이 가능한 순차적 자료구조이다.
배열과는 다르게 값을 추가하거나 삭제하면 크기를 재할당하여 메모리 낭비가 없도록 한다.

#### 특징

1. 논리적 저장 순서와 물리적 저장 순서가 일치한다.
2. index를 사용하여 O(1)에 원하는 원소로 접근이 가능하다.   
   random access가 가능하다고 한다.
3. 값을 추가하거나 삭재하면 값의 수에 맞게 재할당이 일어난다.
5. 메모리 낭비가 없다.

#### 예시

순서대로 10, 20, 30, 40, 50을 Array에 넣은 후 40을 삭제하면   
10, 20, 30, 50 이 된다, 40이 담겨있던 곳이 사라지면서 크기도 5에서 4로 줄어든다.

#### 추가 설명

일반적으로 메모리를 재할당 하는 것은 연산이 오래걸린다.   
차라리 연산이 오래 걸리는 것보다 아래의 연결리스트를 사용하는 것이 더 좋지 않을까?   
저장하는 수가 너무 많을 때 연결리스트를 사용하면 역시 특정 값까지 찾아가는데 너무 오래걸리나?   
등등 여러 의문이 들었는데 순간 아래의 글이 생각났다.   

<https://twitter.com/beebomco/status/967670500116742144>   
고전 슈퍼마리오 게임의 크기는 32KB인데 해당 트위터의 슈퍼마리오 게임 이미지 크기는 445KB라는 것...   

첨단산업이 발달하기 전에는 프로그램의 메모리를 줄어야하는 상황이 아주 많이 있었을 것이다.   
연산이 어찌되었든 메모리가 부족해서 프로그램이 터지는 상황까지 왔다면 상대적으로 많은 메모리를 사용하는 연결리스트도 사용하기 어려웠을 수 있다.   
실재로 옛날 게임 중에서는 메모리 부족으로 인한 버그나 사건사고도 많았고 한다.   
ex) 공포게임 사일런트 힐에서는 마을 구현에만 메모리가 터져서 안개라는 요소를 넣어 시야를 가리고 주인공 근처만 사물을 활성화시켜 메모리를 아꼈다.   
그렇게 생각하니 리스트를 사용하는 이유가 잘 와닿았다...   
~~학교에서도 배열 크기 재할당 가르칠때 위의 그림을 보여주면 좀 더 의욕적으로 했을지도 모르는데 하하핳 ^ㅠ^~~

갑자기 필자는 코딩을 아주 편하게 배우고 있다는 생각이 들었다.

## LinkedList (연결리스트)

노드와 링크를 활용하여 리스트를 구현한 자료구조이다.

### 용어

1. 노드(node) / 버텍스(vertex) : LinkedList의 원소를 부를 때 쓰이는 용어
1. 데이터(Data) : 노드의 값을 저장하는 부분이다. 보통 변수명을 **value**로 한다.
1. 포인터 / 링크(Link) : 동적 할당의 포인터와 같은 의미, 다른 노드의 주소를 저장한다. 보통 변수명을 **next**로 한다.
1. 헤드(Head) : 첫 노드를 의미한다. first라고 표현하기도 한다.
1. 테일(Tail) : 마지막 노드를 의미한다. end라고 표현하기도 한다.

### 설명

**랜덤 접근이 불가능한** 순차적 자료구조이다.   
연결리스트는 노드(node) 혹은 버텍스(vertex)라고 불리는 정보를 담은 작은 객체들로 구성되어 있다.   
노드는 저장할 값(데이터)과 다음 노드를 가리키는 포인터(링크)로 이루어져 있다.   
연결리스트의 헤드(Head)를 시작으로 각 노드의 포인터를 사용하여리스트를 순회할 수 있게 한다.   

삽입 시 아래와 같은 과정을 거친다.   
가장 앞에 노드를 추가해주는 경우도 고려해야 한다.   
<img src="https://user-images.githubusercontent.com/19484971/145765069-ed8f5321-6970-41fa-82f3-6ffc16be80df.png" width="300">

삭제 시 아래와 같은 과정을 거친다.   
삽입과 같이 가장 앞의 노드를 삭제하는 경우도 고려해야 한다.   
<img src="https://user-images.githubusercontent.com/19484971/145765519-12eb8571-5e7b-4fa6-a459-e23abc4b28c9.png" width="300">

### 특징

1. 각 노드의 저장 위치는 관련된 노드의 포인터를 통해서만 알 수 있다.   
   즉, n 번째 원소는 n번의 포인트를 찾아가야 하므로 평균적으로 O(n)의 탐색시간이 걸린다.
2. 삭제나 삽입 자체만 생각하면 연관된 노드의 포인터의 값만 바꿔주면 되므로 O(1)이 걸린다.   
   하지만 삭제나 삽입할 위치를 탐색하는 것이 위에서 말한데로 O(n)의 시간이 걸리므로 결과적으로는 평균적으로 O(n)의 시간이 걸린다.

### 종류

1. Singly Linked List(연결 리스트)   
    + 가장 기본적인 연결리스트
    + 각 노드는 자신의 값과 다음 노드를 가리키는 하나의 포인터를 가진다.

<img src="https://user-images.githubusercontent.com/19484971/145764060-0c6388a1-8715-42f0-add6-af6dfd666b3b.png" width="300">

2. Doubly Linked List(이중 연결 리스트)   
    + 각 노드는 자신의 값과 앞, 뒤 노드를 가리키는 포인터를 가진다.

<img src="https://user-images.githubusercontent.com/19484971/145764587-4c4b242c-5837-461d-ac63-b24dc2bb2667.png" width="400">

3. Circular Linked List(환형 연결 리스트)   
    + 마지막 노드인 테일(Tail)의 포인터를 첫번째 노드로 이어준 연결 리스트이다.
    + 헤드가 없다.

<img src="https://user-images.githubusercontent.com/19484971/145764881-2d348983-8923-48b1-ac9e-872262b410b5.png" width="300">

4. Circular Doubly Linked List(환형 이중 연결 리스트)   
    + 이름 그대로 이중 연결 리스트와 환형 연결 리스트의 특성을 모두 가지는 연결 리스트이다.
    + 헤드의 포인터는 테일을 가리키게 된다.

### 동적배열과 연결리스트의 시간복잡도

|          | List(연결리스트) |	동적배열 |
|----------|------------------|-----------|
| Indexing | O(N) | O(1)|
| Insert / Delete at beginning | O(1) | O(N) |
| Insert / Delete at end | O(1) 마지막 데이터의 주소를 알 때<br> O(N) 마지막 데이터의 주소를 모를때 |	O(1) |
| Insert / Delete in middle |	탐색 시간 + O(1) | O(N) |
| Insert / Delete average | O(N) | O(N)|

개인적으로 동적배열이 가장 뒤에 데이터를 추가할 때 왜 O(1)인지 모르겠다...

### 참조

  + https://opentutorials.org/module/1335/8636
  + https://wayhome25.github.io/cs/2017/04/17/cs-18-1/
  
</br>

## Stack and Queue

선형 자료구조에서 가장 대표적인 데이터 관리 방법인 스택과 큐에 대해서 알아보자! (CS에서는 추상 자료형이라고 서술한다.)
두 자료구조 모두 배열과 링크드 리스트를 활용하여 구현할 수 있으며 기본적인 용어를 꼭 기억하고 넘어가자.

### Stack

먼저 들어간 값이 나중에 나오는 FILO(First In, Last Out / 선입후출)의 특징을 가지는 선형 자료구조이다.

#### 용어

1. FILO(First In, Last Out / 선입후출), LIFO(Last in First Out / 후입선출)   
   스택의 특징을 나타내는 용어로 먼저 들어간 것이 나중에 나오고, 나중에 들어간 것이 먼저 나온다는 의미이다. 스택의 작동 방식을 알면 이해가 쉽다.
3. Top : 가장 위에 존재하는 원소의 위치를 가리키고 있는 인덱스 혹은 포인터 혹은 원소의 값
1. push : 스택에서 값을 삽입하는 메소드
2. pop : 스택에 값을 빼내는 메소드

> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Lifo_stack.png/525px-Lifo_stack.png" width="300">   
위키백과에 있던 스택의 pop과 push 처리를 표현한 사진

#### 특징

1. LIFO(Last in First Out)
   먼저 들어간 원소가 나중에 온다는 의미, 접시를 차곡차곡 쌓아올리고 위에서부터 쓰는 것을 상상하면 된다.

#### 백준 문제 풀이

[10828번 스택](https://www.acmicpc.net/problem/10828)   
깃허브 풀이 링크 : https://github.com/ii200400/algorithm/blob/master/Baekjoon/kotlin/src/10828.kt     
백준 풀이 공유 링크 : http://boj.kr/a6077912babd4197a06ca2ad19a1acc0

[9012번 괄호](https://www.acmicpc.net/problem/9012)   
깃허브 풀이 링크 : https://github.com/ii200400/algorithm/blob/master/Baekjoon/kotlin/src/9012.kt
백준 풀이 공유 링크 : http://boj.kr/ecdf3d7fc35f49ec9bcfe37017345092

[더 많은 스택 문제!](https://www.acmicpc.net/problemset?sort=ac_desc&algo=71)

#### 활용 예시

1. 함수의 지역변수, 매개변수의 메모리 할당 / 해제의 기본 구조로 쓰인다.
2. DFS(깊이우선탐색) 알고리즘에서 사용된다.
3. 문자를 거꾸로 쓰는 프로그램에 사용된다.

### Queue

스택과 대비대는 FIFO(First in First Out / 선입선출)의 특징을 가지는 선형 자료구조이다.

#### 용어

1. enqueue : 큐에 데이터를 저장하는 메소드
2. dequeue : 큐에서 데이터를 빼는 메소드, 큐에 들어있는 데이터 중 가장 오래된 데이터를 가져온다.
3. front : enqueue를 할 때 큐에서 뺄 데이터의 위치
4. rear/back : dequeue를 할 때 큐에 넣을 데이터의 위치
5. Overflow(오버플로우) : 더 이상 큐에 데이터를 저장할 수 없는 상태
6. Underflow(언더플로우) : 큐에 저장된 데이터가 없어서 데이터를 가져올 수 없는 상태

> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/52/Data_Queue.svg/450px-Data_Queue.svg.png" width="300">   
위키백과에 있던 큐를 표현한 그림

#### 특징

1. FIFO(First In First Out / 선입선출)   
   먼저 들어간 데이터가 먼저 나온다는 의미, 버스정류장에서 차례로 버스를 타는 사람들을 생각해보자.

#### 종류

1. Queue   
가장 일반적인 큐

2. Circular Queue(환형 큐)   
배열로 큐를 구현할 때 앞의 남는 저장 공간을 활용하기 위해 환형 배열로 구현한 큐

3. Linked Queue   
LinkedList를 이용해서 만든 큐이다. 오버플로우가 발생하지 않는 것이 특징이다.
그런데 필자는 Linked Queue 라고 부른 적은 없고 그냥 Queue라고 한다. 상관이 없는 것인지는 모르겠다.

</br>

#### 백준 문제 풀이

[10845번 큐](https://www.acmicpc.net/problem/10845)   
깃허브 풀이 링크 : https://github.com/ii200400/algorithm/blob/master/Baekjoon/kotlin/src/10845.kt   
백준 풀이 공유 링크 : http://boj.kr/126316f9f1bb4c8a936f2b8cc41a7315

[1158번 요세푸스 문제](https://www.acmicpc.net/problem/1158)   
깃허브 풀이 링크 : https://github.com/ii200400/algorithm/blob/master/Baekjoon/kotlin/src/1158.kt   
백준 풀이 공유 링크(링크드 리스트) : http://boj.kr/126316f9f1bb4c8a936f2b8cc41a7315   
백준 풀이 공유 링크(큐) : http://boj.kr/13797d6b38d145c487e7727b6ac936e2

[더 많은 큐 문제!](https://www.acmicpc.net/problemset?sort=ac_desc&algo=72)

#### 활용 예시

1. 인쇄기 대기열같은 일반적인 대기줄 / 대기열에 사용된다.
2. DFS(너비우선탐색) 알고리즘에서 사용된다.

</br>

## Priority Queue

스택이나 큐와 비슷한 데이터 관리 방법 중 하나로 각 원소들이 가지고 있는 우선순위들을 기준으로 가장 큰 우선순위를 가지는 원소를 먼저 선택하는 특징을 가지는 추상 자료구조이다. 그래서 이름도 우선순위 큐이다.

이름에 큐가 들어가지만 작동방식에 있어 큐를 활용하는 것도 아니고 크게 연관이 있지는 않다. 또한 우선순위 큐와 아래 서술될 [힙(heap)](https://github.com/ii200400/IT_Skill_Question/tree/master/CS/DataStructure#heap)과 같게 생각하는 경우도 있는데 힙은 우선순위 큐를 구현할 때 거의 항상 사용하는 자료구조일뿐 같은 것은 아니다. 마치 리스트나 스택을 구현할 때 배열과 링크드 리스트를 활용하는 것과 같다.

만일 삽입하는 원소의 우선순위를 (가장 최근에 추가된 원소의 우선순위 + 1)으로 부여하면 스택, (가장 최근에 추가된 원소의 우선순위 - 1)으로 부여하면 큐와 같이 작동하는 것을 쉽게 유추할 수 있다.   
스택과 큐와 같이 데이터를 삽입, 삭제하는 기능과 우선순위 큐에 데이터가 존재하는지(isEmpty) 확인하는 함수가 필수적으로 필요하다.

우선순위 큐는 힙을 통해 구현되어 우선순위를 부여하는 기준에 따라 여러 알고리즘에 활용되는데 이와 관련해서는 [힙](https://github.com/ii200400/IT_Skill_Question/tree/master/CS/DataStructure#heap)을 참고하는 것이 더 좋을 것 같다.

</br>

## Graph

노드(node)와 그 노드를 연결하는 간선(edge)의 집합을 의미한다.   
일반적으로는 객체와 객체 간의 관계를 보여주기 위해서 사용하며 **네트워크 모델**을 만들기 위해서 널리 사용된다고 한다. 트리와 힙 자료구조의 기본이 된다.

### 용어

1. 정점(vertex) / 노드(node) : 그래프 상의 특정 위치나 점을 의미
2. 간선(edge, link, branch) : 노드와 노드를 잇는 선을 의미
3. 자체 간선(self-loops) : 자신에서 시작하여 자신으로 들어오는 간선 <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Graph_single_node.svg/138px-Graph_single_node.svg.png" width="30">
3. 가중치(weight) : 간선에 부여된 비용, 시간, 중요도 등을 의미한다. 언급이 없다면 모든 간선의 가중치가 같다고 생각한다.
3. 인접(adjacent) : 정점 u, v가 있고 이 두 정점을 잇는 간선 e가 있다고 가정할 때 정점 u, v는 e로 인해 서로 인접한다고 말한다.
3. 부속(incident) : 정점 u, v가 있고 이 두 정점을 잇는 간선 e가 있다고 가정할 때 간선 e는 정점 u, v에 부속한다고 말한다.
4. 차수(degree) : 무향 그래프에서 하나의 노드에 연결되어있는 간선의 수
5. 입력차수(in-degree) : 방향 그래프에서 노드로 들어오는 간선의 수
6. 출력차수(out-degree) : 방향 그래프에서 노드에서 나가는 간선의 수
7. 경로(path) : 노드 a에서 노드 b로 가는 과정을 의미한다. 그래프의 모형에 따라 여러 개가 존재할 수 있으며 아예 없을 수도 있다.
8. 경로 길이(path length) : 경로를 구성하는 데 사용된 간선의 수
9. 사이클(cycle, 순환) : 경로의 시작 정점과 종료 정점이 동일한 경우
10. 단순 경로(simple path) : 사이클을 구성하는 노드가 시작 노드와 마지막 노드를 제외하고 중복이 없는 경우
11. 비순환(acycle) : 사이클이 아닌 경우

### 종류

1. 유향 그래프(Directed graph)   
    간선에 방향성이 있는 그래프, 단방향 그래프라고도 한다.
1. 무향 그래프(Undirected graph)   
    간선에 방향성이 없는 그래프, 양방향 그래프라고도 한다.
3. 가중치 그래프(Weighted graph)   
    각 간선에 가중치가 부여된 그래프
4. 완전 그래프(Complete graph)   
    각 노드가 자신을 제외한 모든 노드에 연결된 그래프
5. 밀집 그래프(Dense graph) / 희소 그래프(Sparse graph)   
    노드의 수보다 최대 간선의 수에 가까운 그래프 / 간선의 수가 적은 그래프   
    밀집과 희소 간의 구별이 모호하므로 상황에 따라서 구별을 해야한다.
5. 순환 그래프(Cycle graph) / 비순환 그래프(Acycle graph)   
    사이클인 경로가 하나라도 있는 그래프 / 사이클인 경로가 하나도 없는 그래프
7. **트리(Tree)**   
    한 노드를 가리키는 노드가 하나 이하인 순환 그래프가 아닌 유향 그래프
8. 연결 그래프(Connected graph) / 비연결 그래프(Disconnected graph)   
    무방향 그래프에 있는 모든 정점쌍에 대해서 항상 경로가 존재하는 경우 / 특정 정점쌍 하나라도 경로가 존재하지 않는 경우

### 그래프 표현 방법

|V|는 정점의 수를, |E|는 간선의 수를 의미한다.

#### 1. 인접 행렬(adjacent matrix) - 행렬(2차원 배열)을 사용

NxN BooleanMatrix(일반적으로 2차원 배열로 구현)을 만든 뒤 행렬에 간선의 유무를 저장하는 방식이다.

[구글 이미지를 참고하자](https://www.google.com/search?q=%EC%9D%B8%EC%A0%91%ED%96%89%EB%A0%AC&newwindow=1&sxsrf=AOaemvIRzepLRYD9TlsKcC6u6YB5h-Lwlw:1641110027079&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjz4M2hy5L1AhXTc94KHYKHCK4Q_AUoAXoECAgQAw&biw=1536&bih=722&dpr=1.25)

+ 특정 노드와 노드 사이의 간선의 유무는 O(1)로 파악할 수 있다. 
+ 특정 노드에서 인접한 모든 노드를 찾는 속도는 O(|V|)로 느린편이다. 
+ 모든 노드에 관해 인접한 노드를 찾는 속도는 O(|V|^2)로 느린편이다.   
+ 공간 복잡도는 O(|V|^2)이다.
+ Dense graph를 표현할 때, 정점 간의 연결 유무 참고가 많을 때 사용하기 좋다.

#### 2. 인접 리스트(adjacent list) - 연결 리스트 사용

각 정점과 인접한 정점들을 연결 리스트를 사용하여 표현한는 방법이다.

[구글 이미지를 참고하자](https://www.google.com/search?q=%EC%9D%B8%EC%A0%91%EB%A6%AC%EC%8A%A4%ED%8A%B8&tbm=isch&ved=2ahUKEwjUq5miy5L1AhVBXZQKHWWSCtQQ2-cCegQIABAA&oq=%EC%9D%B8%EC%A0%91%EB%A6%AC%EC%8A%A4%ED%8A%B8&gs_lcp=CgNpbWcQAzIFCAAQgAQyBQgAEIAEMgUIABCABDIGCAAQBRAeMgQIABAYMgQIABAYMgQIABAYMgQIABAYMgYIABAFEB4yBggAEAUQHjoHCCMQ7wMQJzoGCAAQBxAeUKZBWJZFYJtGaANwAHgCgAGfAYgB7AeSAQMwLjiYAQCgAQGqAQtnd3Mtd2l6LWltZ8ABAQ&sclient=img&ei=DFrRYdT1EsG60QTlpKqgDQ&bih=722&biw=1536)

+ 간선의 유무는 해당 노드의 차수만큼의 시간이 걸린다, 최악의 경우 O(V)   
+ 특정 노드에 인접한 모든 노드를 찾는 속도 또한 해당 노드의 차수만큼의 시간이 걸린다.
+ 모든 노드에 관해 인접한 노드를 찾는 속도는 O(|V|+|E|)이다.   
+ 공간 복잡도는 O(|E|)이다.
+ Sparse graph를 표현할 때, 정점 수가 많을 때 사용하기 좋다.

개인적으로 공간 복잡도가 O(|V|+|E|)이라고 생각했는데.. 왜 O(|E|)인지 잘 모르겠다.

</br>

### 그래프 알고리즘 관련 링크

+ [그래프를 탐색하는 알고리즘](https://github.com/ii200400/IT_Skill_Question/blob/master/CS/Algorithm/README.md#graph-search)
+ [그래프의 특정 간선만을 선택하여 비용이 가장 작은 트리를 만드는 알고리즘](https://github.com/ii200400/IT_Skill_Question/blob/master/CS/Algorithm/README.md#minimum-spanning-tree-mst-%EC%B5%9C%EC%86%8C-%EC%8B%A0%EC%9E%A5-%ED%8A%B8%EB%A6%AC)
+ [노드에서 노드까지 가는데 가장 적은 비용을 찾는 알고리즘](https://github.com/ii200400/IT_Skill_Question/blob/master/CS/Algorithm/README.md#%EA%B7%B8%EB%9E%98%ED%94%84-%EC%B5%9C%EB%8B%A8-%EA%B2%BD%EB%A1%9C-%EB%AC%B8%EC%A0%9C) 

</br>

## Tree

그래프의 일종으로 한 노드를 가리키는 노드가 하나 이하인 순환 그래프가 아닌 유향 그래프   
기본적으로 그래프이기 때문에 배열과 링크드 리스트로 구현이 가능하다.   
계층적 관계를 나타내는 모델을 위해서 만들어졌다. ex) 디렉터리 구조
  
<img src="https://upload.wikimedia.org/wikipedia/commons/5/5f/Tree_%28computer_science%29.svg" width="200">   
위키백과에 있던 트리 사진

### 용어

  + Node (노드) : 트리를 구성하고 있는 각각의 요소
  + Edge (간선) : 트리를 구성하기 위해 노드와 노드를 연결하는 선
  + Root Node (루트 노드) : 트리 구조에서 최상위에 있는 노드, 유일하게 부모가 없는 노드
  + leaf Node (=Terminal Node, 단말 노드) : 자식이 없는 노드, 단말(Terminal) 혹은 잎(Leaf)이라고 부른다.
  + Internal Node (내부노드, 비단말 노드) : 단말 노드를 제외한 모든 노드 (루트 노드를 포함)
  + level (레벨) : 트리의 각 층의 단계, 루트 노드의 레벨은 1이다.
  + Depth (깊이) : 루트 노드에서 특정 노드까지 사용되는 간선의 최소 수, 루트노드의 깊이는 0 이다.
  + Height (높이) : 특정 노드부터 단말 노드까지의 거리
  + Parent (부모) : 특정 노드보다 레벨이 낮으면서 간선으로 연결되어있는 노드
  + Child (자식) : 특정 노드보다 레벨이 높으면서 간선으로 연결되어있는 노드
    + A 노드가 B 노드의 부모 노드라면 B 노드는 A 노드의 자식 노드이다.
  + Sibling (자매) : 같은 부모를 갖는 노드
    + A 노드에게 B와 C의 자식 노드가 있다면 B와 C는 자매이다.
  + Ancestors (조상) : 루트 노드에서 특정 노드까지 갈 때, 경로에 있는 모든 노드
  + Descendant(후손): 특정 노드에서 갈 수 있는 모든 노드
  + Degree (차수) : 특정 노드의 자식 수
  + 트리의 차수: 트리의 모든 노드 중에 가장 높은 차수
  
### 특징

+ 계층 구조를 가진다.
+ 사이클이 존재하지 않는 유향 그래프이다.
+ 트리에는 하나의 루트 노드만이 존재하고 모든 자식 노드는 한 개의 부모 노드만이 있다.
+ 루트 노드에서 다른 노드까지의 경로는 반드시 하나만 존재한다.
+ 간선의 수는 항상 트리에 있는 노드의 수의 + 1 개 이다.
  
### 종류
  
  + Binary Tree (이진 트리) : 트리 내의 모든 노드의 차수가 2 이하인 트리, 아래에 자세하게 서술하였다.
  + B-Tree : 이진 트리를 확장하여 하나의 노드가 가질 수 있는 자식 노드의 최대 숫자가 2보다 큰 트리
  + Forest (포레스트) : n개의 disjoint tree의 집합, 간단히 트리가 여러 개 있다고 생각하자.
  + Trie (트라이) : 각 노드에 문자를 저장하여 접두사를 빠르게 찾기 위한 트리   
    (문자열을 저장하는 자료구조에서 가장 효율적인 문자열 검색을 위한 트리이다.)
  + Balanced Tree (균형 트리) : 단말 노드들이 가능한 한 최소 높이를 가지는 트리
  + Sub Tree (서브 트리) : 하나의 노드와 그 노드의 후손들로 이루어진 트리
  + Skewed Binary Tree (편향 트리) : 노드가 한쪽으로만 추가된 듯 기울어진 트리

### 참고

  + https://gmlwjd9405.github.io/2018/08/12/data-structure-tree.html

</br>

## Binary Tree

모든 노드의 최대 자식 수가 2인 트리, 트리를 대표하는 가장 기본적인 트리 중 하나이다.

### 트리 순회

부모 노드의 방문 순서에 따라서 이름이 바뀐다. 또한 왼쪽 자식 노드을 오른쪽 자식 노드보다 항상 먼저 방문하도록 한다.

  + 전위 순회 (Pre-order traversal) : 부모 노드 - 왼쪽 자손 노드 -  오른쪽 자손 노드 순서로 방문
  + 중위 순회 (In-order traversal) : 왼쪽 자손 노드 - 부모 노드 - 오른쪽 자손 순서로 방문
  + 후위 순회 (Post-order traversal) : 왼쪽 자손 노드 - 오른쪽 자손 노드 - 부모 노드 순서로 방문
  + 레벨 순서 순회(Level-order traversal): 너비 우선 순회(Breadth-First traversal)라고도 한다. 노드를 레벨 순서로 방문하는 순회 방법.
  
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Sorted_binary_tree_ALL_RGB.svg/440px-Sorted_binary_tree_ALL_RGB.svg.png" width="300">   

위키백과에 있던 트리 순회 사진   

중위 순회는 F, B, A, D, C, E, G, I, H   
전위 순회는 A, B, C, D, E, F, G, H, I   
후위 순회는 A, C, E, D, B, H, I, G, F   
이라고 서술되어있다.

참고로 레벨 순서 순회는 큐로 구현이 가능하고 나머지는 모두 스택으로 구현이 가능하다.

### 종류

트리 용어는 잘 표준화되어 있지 않아서 글마다 차이가 있다. 나는 위키백과를 기준으로 서술할 것이다.   
perfect는 포화, complete는 완전, full은 전 으로 해석되어버려 개인적으로 심각하게 햇갈린다;;

  + Full Binary Tree (전 이진 트리) : 모든 노드가 0개 또는 2개의 자식 노드를 갖는 트리
  + Complete Binary Tree (완전 이진 트리) : 마지막 높이를 제외한 모든 높이에서 노드가 꽉 차 있는 이진 트리   
    마지막 높이의 노드는 모두 채워져 있지 않아도 되는 대신 왼쪽에서 오른쪽으로 빠짐없이 채워져야 한다.
    + Heap Tree (힙 트리) :  보통 '힙(heap)'이라고 줄여 부르며 최대값(최소값)을 빠르게 찾기 위해 만들어졌다.
  + Perfect Binary Tree (포화 이진 트리) : 모든 리프 노드의 높이가 같은 트리
  + Binary Search Tree (이진 탐색 트리) : 모든 노드가 아래의 조건을 충족하는 트리   
    "왼쪽 자식 노드의 데이터 값 <= 부모 노드의 데이터 값 < 오른쪽 자식 노드의 데이터 값"
  
</br>

### 백준 문제 풀이

[1991번 트리 순회](https://www.acmicpc.net/problem/1991)   
트리 순회를 코드로 구현해보는 간단한 문제   
깃허브 풀이 링크 : https://github.com/ii200400/algorithm/blob/master/Baekjoon/kotlin/src/1991.kt   
백준 풀이 공유 링크 : http://boj.kr/e29052fb5ff44b208b7d5d818d246449   

[4256번 트리](https://www.acmicpc.net/problem/4256)   
전위/중위 순회를 입력하면 후위순회를 출력하는 문제
깃허브 풀이 링크 : https://github.com/ii200400/algorithm/blob/master/Baekjoon/kotlin/src/4256.kt   
백준 풀이 공유 링크 : http://boj.kr/71af77b8d2c94f4fbccc52d222b536e0   

## Heap

**완전 이진 트리 종류 중 하나**로 Priority Queue(우선순위 큐)를 위해서 만들어진 자료구조이다.
이를 위하여 부모와 자식 간의 데이터 값에 조건이 있으며 이 조건을 충족시키기 위해서 **heap의 구조를 유지하는 것을 heapify**라고 한다.

### 구현 방법

배열을 사용한다는 전제로 서술하면..

  1. 인덱스 0은 비운 채로 1부터 노드의 데이터 값을 넣는다. (0부터 채워도 되지만 편의상)
  2. 부모와 자식 간의 노드의 인덱스에는 다음과 같은 관계가 있다. heapify를 할 때 아래의 관계를 참고하여 구현한다.   
    - 왼쪽 자식의 인덱스 = (부모의 인덱스) * 2 (인덱스 0을 채울 경우 왼쪽 자식의 인덱스 = (부모의 인덱스) * 2 + 1)   
    - 오른쪽 자식의 인덱스 = (부모의 인덱스) * 2 + 1 (인덱스 0을 채울 경우 오른쪽 자식의 인덱스 = (부모의 인덱스) * 2 + 2)   
    - 부모의 인덱스 = (자식의 인덱스) / 2 (인덱스 0을 채울 경우 부모의 인덱스 = (자식의 인덱스 - 1) / 2)   

### heapify 과정

노드를 삽입 했을 때
  
1. 트리의 가장 마지막 부분에 데이터를 삽입한다.
2. 부모 노드와 삽입 부분 노드의 대소 비교를 하여 힙의 규칙에 맞지 않는 경우 서로 자리를 바꾼다.   
   (보통은 왼쪽 자식을 우선으로 바꾼다.)
3. 새롭게 들어간 데이터가 힙의 규칙에 맞는 자리를 찾을 때까지 2번의 과정을 반복한다.
  
노드를 삭제 했을 때
  
1. 삭제할 원소를 삭제 한 후 트리의 가장 마지막 원소를 삭제된 데이터의 위치에 넣어준다.
2. 두 개의 자식 노드와 대체로 들어간 원소의 대소 비교를 하여 힙의 규칙에 맞지 않는 경우 서로 자리를 바꾼다. (세 노드 중 가장 큰 값이 부모 노드가 되도록 자리를 바꾼다.)   
3. 데이터가 힙의 규칙에 맞는 자리를 찾을 때까지 2번의 과정을 반복한다.

### 특징

  + 중복된 값을 허용한다. (아래 서술할 이진 탐색 트리에서는 중복된 값을 허용하지 않는다.)
  + 값을 모두 정렬하지 않는다. 단지, 가장 큰(작은) 값만 빠르게 찾을 뿐이다.
  + 최댓값이나 최솟값을 찾는데 O(1)의 시간 복잡도로 아주 빠른 편이다.
  + 노드가 삭제되거나 삽입되면 heapify 과정이 필요한데 이는 O(log n)이 걸린다.

### 종류

  + Max Heap (최대 힙) : 부모 노드가 자식노드보다 크거나 같은 값을 가지는 조건을 가진 완전 이진 트리
  + Min Heap (최소 힙) : 부모 노드가 자식노드보다 작거나 같은 값을 가지는 조건을 가진 완전 이진 트리

### 백준 문제 풀이

[1927번 최소 힙](https://www.acmicpc.net/problem/1927)   
단순하게 최소 힙을 구현하는 문제   
깃허브 풀이 링크 : https://github.com/ii200400/algorithm/blob/master/Baekjoon/kotlin/src/1927.kt   
백준 풀이 공유 링크 : http://boj.kr/ca51b177328f494c8ea742e2bc991c4f   

[2220번 힙 정렬](https://www.acmicpc.net/problem/2220)   
heapify 과정을  알고 있어야 해결이 가능한 문제
깃허브 풀이 링크 : https://github.com/ii200400/algorithm/blob/master/Baekjoon/kotlin/src/2220.kt
백준 풀이 공유 링크 : http://boj.kr/de1d077d0ba8473c9a118579410136f4


### 참고

[자바 [JAVA] - 힙 정렬 (Heap Sort)](https://st-lab.tistory.com/225)

</br>

## BST - Binary Search Tree (이진 탐색 트리)

데이터를 효율적으로 탐색하기 위해서 데이터를 저장하는 규칙이 있는 트리이다.   
탐색이 Worst Case에 걸리지 않도록 하기 위해서 Rebalancing 기법이 사용되기도 하며   
이러한 알고리즘을 가진 트리를 <code>자가균형 이진탐색트리</code> 라고 한다.   
기본적으로 이진 트리의 모양을 가지고 있으며 다음과 같은 규칙이 있다.

### 규칙

1. 이진 탐색 트리의 노드에 저장된 키는 유일하다.
2. 루트 노드의 키가 왼쪽 서브 트리를 구성하는 어떠한 노드의 키보다 크다.
3. 루트 노드의 키가 오른쪽 서브 트리를 구성하는 어떠한 노드의 키보다 작다.
4. 왼쪽과 오른쪽 서브트리도 이진 탐색 트리이다.

### 특징

  + 데이터 값의 중복이 허용되지 않는다.
  + 중위 순회를 하면 작은 값에서 큰 값 순으로 데이터를 방문할 수 있다.
  + 탐색 연산에 O(lon n)(사실은 O(h))의 시간 복잡도가 필요하다.
  + 데이터가 한쪽으로만 몰린 편향 트리가 될 수 있다. 이 경우 Worst Case가 되며 시간 복잡도는 O(n)이 된다.

### 종류

  + 자가균형 이진탐색트리 : 이름 그대로 스스로 균형 트리가 되도록 만드는 이진 탐색 트리   
    best/worst case에서 탐색/삽입/삭제 모두 시간 복잡도가 O(log N)인 것이 특징이다.
    + AVL Tree : 가장 처음으로 나온 자가 균형 이진 탐색 트리, 아래의 트리와 비교하여 삽입과 제거가 느리고 탐색 자체는 빠르다.
    + Red-Black Tree : 노드에 색깔 속성이 붙은 트리   
      구현은 복잡하지만 매우 효율이 좋기 때문에 자가균형 이진탐색트리를 만든다면 이것이 자주 쓰인다.

</br>

## Red-Black Tree - RBT

BST를 기반으로 하는 트리이다.   
위에서 서술한 대로 트리의 높이를 최소화하여 시간 복잡도를 줄이는 것이 핵심인 트리이다.   
상당히 규칙이 많아서 구현하기 복잡한데 그 규칙을 아래에 서술한다.

### 규칙

0. 노드의 자손이 없을 경우 자손를 가리키는 포인터는 널(NULL)값을 저장한다. 이 널값들을 단말 노드로 간주한다.
1. 노드는 Red or Black이라는 색깔을 갖는다.
2. 루트 노드의 색깔은 Black이다.
3. 모든 단말 노드의 색은 black이다.
4. 어떤 노드의 색깔이 red라면 그 노드의 자식 노드 색은 모두 black 이다. (red 색을 가지는 노드는 연속으로 존재할 수 없다.)
5. 임의의 한 노드에서 단말 노드까지의 모든 경로에는 단말 노드를 제외하고 항상 같은 수의 블랙 노드가 있다.\
이 수를 Black-Height라고 한다.

### 특징

  + 이진 탐색 트리와 균형 트리의 특징을 모두 가지고 있다.
  + 이상적인 상황에서나 최악의 상황에서 탐색/삽입/삭제 모두 시간 복잡도가 O(log N)이다.
  
### 삽입 방법

1. 삽입하는 노드의 색을 Red로 지정(Black-Height에 영향을 끼치지 않으므로)하고 우선 BST의 조건을 지키면서 노드를 넣는다.   
1. Black-Height 조건에 맞지않으면 rotation(트리 회전이라고 불린다.)을 통해 height 를 조정하고 연속으로 Red 노드가 있다면 색을 조정한다.

사진의 Case 1이 Black-Height 조건에 맞지 않았을 때 / Case 2가 연속으로 Red인 노드가 있을 때 조정하는 방법이다.   
대문자들은 A<B<C인 조건을 가지는 내부 노드이고 소문자들은 단말 노드(NULL)을 나타낸다.   
가장 아래의 Red 노드가 삽입된 상태에서 조정하면 왼쪽과 같은 트리가 된다.

<img src="../image/1.1%20Graph25.png" width="40%" height="40%"> <img src="../image/1.1%20Graph26.png" width="40%" height="40%">

*삭제 방법은 생략하겠다.*

</br>

## HashTable (해시 테이블)

HashTable 또는 HashMap이라고 불린다.   
연관배열 구조를 이용하여 키(key)를 알고있으면 대응하는 값(value)을 빠르게 찾을 수 있는 자료구조이다.   
키는 임의의 길이를 가지는 데이터이므로 그대로 사용하면 저장할 공간이 낭비되므로 고정된 길이를 가지는 해시값으로 바꿔준다.

#### 용어

  + Key (키) : 임의의 길이를 갖는 데이터이며 중복이 불가능하다.
  + Value (값) : 키와 매칭되어 저장되는 데이터를 의미한다.
  + 연관배열 구조 (Associative Array) : 키(key) 데이터와 값(value) 데이터가 1:1로 연관되어 있는 자료구조이다. 다음과 같은 기능이 있다.
    + 키(key)와 값(value)이 주어졌을 때, 연관 배열에 그 두 값(key & value)을 저장한다.
    + 키(key)가 주어졌을 때, 연관되는 값(value)을 얻을 수 있다.
    + 키(key)와 새로운 값(value)이 주어졌을 때, 원래 키에 연관된 값(value)을 새로운 값(value)으로 교체할 수 있다.
    + 키(key)가 주어졌을 때, 그 키(key)에 연관된 값(value)을 제거할 수 있다.
  + Hash Function (해시함수) : 키를 입력으로 받아서 해시값을 반환한다.   
    입력되는 데이터의 범위보다 출력되는 데이터의 범위가 좁다는 특징이 있으며 이 때문에 서로 다른 키에서 값은 해시값이 나올 수도 있다. 
  + Hash (해시값) : 해시 함수에서 나온 결과 값이다. 값들은 고정된 길이를 가지게 되며 저장소의 위치를 의미한다.   
    해시 코드(hash code), 해시 섬(hash sum), 체크 섬(check sum) 등으로도 불린다.
  + Bucket (=Slot, 버킷) : 값(value)이 저장되는 곳이다.
  + Collision (충돌) : 해시 함수에서 다른 키로 같은 해시값이 생성되어 이미 사용하고 있는 저장소 위치에 접근하는 상황을 해시 충돌이라고 한다.
  
  <img src="../image/1.1%20Graph29.png" width="50%" height="50%">

#### 좋은 Hash Function 조건

1. 키(key)에 대응하는 값(value)은 1:1 대응이 **아닌 것**이 좋다.   
    현실적으로 불가능하기도 하지만 메모리도 많이 소비하며 차라리 그냥 배열을 사용하는 것이 좋다.
2. Collision이 적을 수록 좋다.   
    충돌이 많아질 수록 시간 복잡도가 O(1)에서 O(n)에 가까워지기 때문이다.

    즉, 해시 테이블은 충돌이 불가피하며 충돌을 적게하는 함수를 선택하고 충돌을 해결하는 방법을 아는 것이 중요하다.

### Collision Resolution

충돌을 해결하기 위한 다양한 방법이 있지만 기본적으로 크게 두 가지 방식으로 충돌 해결법을 나눌 수 있다.

#### 1. Open Address (개방 주소법)

공개 주소 방식이라고도 불린다.   
충돌이 일어난 경우 다른 비어있는 버킷에 자료를 넣는 방법이다.   
Worst Case라면 슬프게도 빈 공간을 찾지 못하고 원래자리로 돌아올 수 있다.   
대표적으로 3가지 종류가 있는데 다음과 같다.

##### 1-1. Linear Probing (선형 탐색)

순차적으로 비어있는 버킷을 찾을 때까지 계속 탐색한다.   
처음 탐색한 위치를 f(k)이라고 하면 다음과 같이 탐색한다.   
 f(k) + 1 -> f(k) + 2 -> f(k) + 3 -> ...
 
 <img src="../image/1.1%20Graph27.png" width="50%" height="650%">

##### 1-2. Quadratic probing (제곱 탐색)

순차적으로 탐색하지 않고 제곱한 값을 더하면서 탐색한다.   
처음 탐색한 위치를 f(k)이라고 하면 다음과 같이 탐색한다.   
f(k) + 1² -> f(k) + 2² -> f(k) + 3² -> ...

##### 1-3. Double hashing probing (이중 탐색)

해쉬 함수에서 충돌이 발생하면 다른 해쉬 함수를 이용해 새로운 주소를 할당한다. 위 두 가지 방법에 비해 많은 연산량을 요구하게 된다.

+ 특징
    + 해시테이블 자체에서 데이터 저장 및 처리가 가능하다.
    + 해시 함수의 성능이 전체 해시테이블의 성능을 좌지우지한다.
    + 저장소가 늘어나지 않는 이상 저장할 수 있는 데이터 양도 한정되어있다.
    + 삽입/삭제/탐색 모두 최상의 경우 O(1), 최악의 경우 O(n)의 시간 복잡도를 가진다.

#### 2. Separate Chaining (분리 연결법)

줄여서 체이닝(Chaining)이라고 하기도 하며 일반적으로 Open Address 보다 Separate Chaining이 더 빠르다.   
Open Address 의 경우 빈 버킷을 적어질수록 Worst Case 발생 빈도가 더 높아지기 때문이다.   
동일한 해쉬 값에 대해 여러 값을 저장하여 충돌을 해결하는 방법이다.   
링크드 리스트나 트리를 사용하여 구현할 수 있다.

##### 2-1. 연결 리스트를 사용하는 방식 (Linked List)

각 버킷을 연결리스트(Linked List)로 만들어 Collision 이 발생하면 해당 버킷의 연결리스트에 추가하는 방식이다.   
버킷을 그대로 사용하는 Open Address 방식에 비해 테이블의 확장을 늦출 수 있다.

##### 2-2. 트리를 이용하는 방식 (Red-Black Tree)

위와 같은 방식으로 동작하지만 연결 리스트 대신에 트리를 사용하는 방법   
한 버킷에 저장된 데이터 수가 많을수록 위의 방법보다 효율적이다.   
반대로 데이터 수가 적다면 연결 리스트를 사용하는 것이 메모리를 절약할 수 있다.

<img src="../image/1.1%20Graph28.png" width="60%" height="60%">

+ 특징
  + 한 버킷에 여러 데이터가 저장될 수 있어 한정된 해시 테이블에서 더 많은 데이터를 저장할 수 있다.
  + 연결 리스트의 특성과 같이 데이터의 크기가 동적이다.
  + 해시 함수를 선택하는 중요성이 상대적으로 적다.
  + 한 버킷에만 데이터가 몰리면 성능이 저하된다.
  + 추가적인 저장공간(연결리스트)를 사용하므로 추가적인 연산이 필요하다.
  + 1개의 Bucket당 평균적으로 a개의 데이터가 들어있다고 할 때   
    head에 삽입할 때에는 O(1), tail에 삽입할 때에는 BestCase O(a)/ WorstCase O(n)의 시간 복잡도를 가진다. 
    탐색/삭제는 BestCase O(a), WorstCase O(n)의 시간 복잡도를 가진다.
    
##### Open Address vs Separate Chaining

1. 일단 두 방식 모두 Worst Case 에서 O(N)이다.
2. Open Address방식은 연속된 공간에 데이터를 저장하기 때문에 Separate Chaining에 비해 캐시 효율이 높다.   
   즉, 데이터의 개수가 충분히 적다면 Open Address방식이 Separate Chaining보다 더 성능이 좋다.
3. 버킷의 크기가 정적인 Open Address 방식에 비해 Separate Chaining 방식이 테이블의 확장을 보다 늦출 수 있다.
    
##### 기타

  + 보조 해시 함수 :  Separate Chaining 방식을 사용할 때, 해시값을 변형하여 해시 충돌 가능성을 줄이는 것이다.
  + load factor : 해시 버킷의 수가 저장하는 데이터 수에 비해서 적어서 충돌이 많이 일어난다면 해시 버킷의 수를 증가시키면 되는데 그러한 임계점을 의미한다.   
    예를들어서 100개의 버킷이 있는 해시 테이블에서 75개의 버킷이 사용될때 해시 버킷을 동적 확장한다고 하면 load factor는 0.75이다.
  
##### 참조

  + https://velog.io/@cyranocoding/Hash-Hashing-Hash-Table%ED%95%B4%EC%8B%9C-%ED%95%B4%EC%8B%B1-%ED%95%B4%EC%8B%9C%ED%85%8C%EC%9D%B4%EB%B8%94-%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0%EC%9D%98-%EC%9D%B4%ED%95%B4-6ijyonph6o
