# 1-1. 자료구조
+ Array and LinkedList
+ Stack and Queue
+ Graph
+ Tree
+ heap
+ Hash

*****

## 자료구조의 필요성

    전산학에서 자료를 효율적으로 이용할 수 있도록 컴퓨터에 저장하는 방법이다. 
    신중히 선택한 자료구조는 보다 효율적인 알고리즘을 사용할 수 있게 한다. 
    이러한 자료구조의 선택문제는 대개 추상적 자료구조의 선택으로부터 시작하는 경우가 많다. 
    효과적으로 설계된 자료구조는 실행시간 혹은 메모리 용량 등의 자원을 최소한으로 사용하면서 연산을 수행하도록 한다. 
    - 위키백과 -

즉, 제한된 컴퓨터 자원에서 최대한의 효율을 뽑기 위해서 만들어진 선조들의 노오력의 산물이라는 것이다.\
cpu와 메모리가 끔찍할 정도로 강력해진 현재에 와서는 그 필요성이 많이 줄어들었지만 여전히 컴퓨터에서 너무나도 중요한 내용이다.\
같은 문제를 풀어도 자료구조를 아는 사람이 모르는 사람보다 더 짧은 코딩으로 더 빠른 알고리즘을 만드는 경우가 많으며\
아무리 cpu와 메모리가 강력해진다 하더라도 그만큼 사람들이 더 어려운 문제를(빅데이터, AI 등) 컴퓨터를 활용하여 처리하기 때문이다.

코드 구현부분은 제외하였다. 페이지가 너무 길어지고 아니라 구현방법도 사람마다 다르다.\
필자는 개인적으로 알고리즘을 코딩테스트가 가능한 사이트에서 알고리즘을 먼저 공부하고 자료구조를 공부하는 것을 추천한다.\
여기에 서술할 자료구조 정도는 코통 코딩테스트에서 못해도 한번씩은 다루며 \
코딩을 하는 과정에서 자료구조를 자연스럽게 습득하는 경우가 많기 때문이다.

**<code>꼭 자료구조 종류의 특징과 유사한 자료구조 간의 차이점을 중심으로 읽고
다른 카테고리(DB, 네트워크 등)의 기본이 됨을 기억하자!</code>**

*****

## Array and LinkedList

+ 시작하기 전에..

Array와 LinkedList 가장 흔하게 볼 수 있는 순차적(선형) 자료구조이다. \
그런데 공부를 하다가 ArrayList라는 단어를 보고 의아함을 느껴 깊이 알아보게 되었다.

ArrayList는 자바에서 쓰이는 List라는 이름의 인터페이스를 상속받은 클래스이다. \
즉, 자바에서만 쓰이는 클래스이지 자료구조에서 말하는 Array는 아..닌 것 같다.. 솔직히 잘 모르겠다.

추가적으로 List는 자료구조 취급을 받지 않는다.\
List는 추상적인 개념일 뿐이고 List를 구현하기 위해서 Array와 LinkedList를 사용한다고 말한다.\
참고로 위키백과에서는 List를 **중복이 가능한 일련의 값이 모여있는 추상적 자료형**이라고 써놓았다.

비슷하게 혼란스러운 것이 Queue(큐)와 Priority Queue(우선순위 큐)이다.\
큐는 자료구조가 맞는데 우선순위 큐는 추상적 개념으로 배열이나 힙 등으로 구현이 가능하다.\
**도데체 왜 이렇게 혼란스러운 상황이 되었는지 꽤나 화난다. 이해하는데 5일정도 걸린 것 같다.**

### Array
가장 기초적인 자료구조이다.\
선형 자료 구조는 이것으로 구현이 모두 가능하고 일부 비선형도 꽤 비효율적이지만 구현은 가능하다.

+ 용어
1. Index(인덱스) : 배열에 저장한 값의 위치를 의미

+ 설명

Index를 이용하여 랜덤 접근이 가능한 순차적 자료구조이다.\

+ 특징

1. 논리적 저장 순서와 물리적 저장 순서가 일치하는 순차적인 자료구조이다. 
2. 위의 이유로 index를 사용하여 O(1)에 원하는 원소로 접근이 가능하다. \
  random access가 가능하다고 한다.
3. 원소의 삭제, 삽입은 O(1)에 끝나지만 자리를 채우거나 비우기 위하여 자료들을 한 칸씩 옮기는 과정에서 O(N)이 소모된다.
4. 재할당을 하지 않는 이상 최대 원소의 갯수는 제한적이다.

+ 예시

순서대로 10, 20, 30, 40, 50을 Array에 넣은 후 40을 삭제하면 다음의 그림이 된다.
![Array1](../image/1.1%20Array1.png)

### LinkedList (연결리스트)

+ 용어
1. 노드(node) / 버텍스(vertex) : LinkedList의 원소를 부를 때 쓰이는 용어
1. 데이터(Data) : 노드의 값을 저장하는 부분이다. 보통 변수명을 **value**로 한다.
1. 포인터 / 링크(Link) : 동적 할당의 포인터와 같은 의미, 다른 노드의 주소를 저장한다. 보통 변수명을 **next**로 한다.
1. 헤드(Head) : 첫 노드를 가리키는 **포인터**. first라고 표현하기도 한다.
1. 테일(Tail) : 마지막 **노드**를 의미한다. end라고 표현하기도 한다.

+ 설명

**랜덤 접근이 불가능한** 순차적 자료구조이다.\
연결리스트는 노드(node) 혹은 버텍스(vertex)라고 불리는 것들로 구성되어 있다.\
노드는 저장할 값(데이터)과 다음 노드를 가리키는 포인터(링크)로 이루어져 있다.\
연결리스트의 헤드(Head)를 시작으로 각 노드의 포인터를 사용하여리스트를 순회할 수 있게 한다.\
**트리(Tree)와 그래프(Graph)의 기본 자료형이다.**

+ 특징

1. 각 노드의 저장 위치는 관련된 노드의 포인터를 통해 알 수 있다.\
  즉, n 번째 원소는 n-1번의 포인트를 찾아가야 하므로 O(n)의 탐색시간이 걸린다.
2. 삭제나 삽입 자체만 생각하면 연관된 노드의 포인터의 값만 바꿔주면 되므로 O(1)이 걸린다.\
  하지만 삭제나 삽입할 위치를 탐색하는 것이 위에서 말한데로 O(n)의 시간이 걸리므로 결과적으로는 O(n)의 시간이 걸린다.
3. 노드를 동적으로 추가, 삭제할 수 있다. (메모리 영역 중 힙(heap)영역이 충분하다면..)

+ 예시 사진

순서대로 10, 20, 30, 40를 LinkedList에 넣었을 때 다음의 그림이 된다.
![LinkedList1](../image/1.1%20LinkedList1.png)

+ 종류
1. Linked List(연결 리스트)\
가장 기본적인 연결 리스트
2. Doubly Linked List(이중 연결 리스트)\
각 노드에 이전 노드를 가리키는 포인터를 하나 더 추가한다. 노드들은 두 개의 포인터를 가지게 된다.
3. Circular Linked List(환형 연결 리스트)\
마지막 노드인 테일(Tail)의 포인터를 첫번째 노드로 이어준 연결 리스트이다.
4. Circular Doubly Linked List(환형 이중 연결 리스트)\
이름 그대로 이중 연결 리스트와 환형 연결 리스트의 특성을 모두 가지는 연결 리스트이다.

#### 참조
  + https://opentutorials.org/module/1335/8636
  + https://wayhome25.github.io/cs/2017/04/17/cs-18-1/
  
*****

## Stack and Queue

+ 설명

추가와 삭제에 대하여 원소의 순서가 영향을 끼치는 선형 자료구조이다.\
나도 이과라서 글은 잼병이고 잘 못쓰겠으니 그냥 아래 설명을 보자.

### Stack

+ 용어
1. Top : 가장 위에 존재하는 원소의 위치를 가리키고 있는 인덱스 혹은 포인터.

+ 특징
1. 먼저 들어간 원소가 먼저 나오는 LIFO(Last In First Out) 조건을 가진다.

+ 예시 사진

![Stack1](../image/1.1%20Stack1.png)

+ 활용 예시
1. 함수의 지역변수, 매개변수의 메모리 할당 / 해제의 기본 구조로 쓰인다.
2. DFS(깊이우선탐색) 알고리즘에서 사용된다.
3. 문자를 거꾸로 쓰는 프로그램에 사용된다.

### Queue

+ 용어
1. enqueue : 큐에 데이터를 저장한다는 의미. 
2. dequeue : 큐에서 데이터를 뺀다는 의미. 큐에 들어있는 데이터 중 가장 오래된 데이터를 가져온다.
3. front : enqueue를 할 때 큐에서 뺄 데이터의 위치를 의미한다.
4. rear : dequeue를 할 때 큐에 넣을 데이터의 위치를 의미한다.
5. Overflow(오버플로우) : 더 이상 큐에 데이터를 저장할 수 없는 상태
6. Underflow(언더플로우) : 큐에 저장된 데이터가 없어서 데이터를 가져올 수 없는 상태

+ 특징
1. 나중에 들어간 원소가 먼저 나오는 LIFO(Last In First Out) 조건을 가진다.

+ 종류
1. Queue\
가장 일반적인 큐

(아래사진은 위에서 아래, 왼쪽에서 오른쪽 순서이다.)\
<img src="../image/1.1%20Queue1.PNG" width="50%" height="50%">

2. Circular Queue(환형 큐)\
큐의 남는 저장 공간을 활용하기 위한 방식.

(아래사진은 왼쪽에서 오른쪽, 위에서 아래 순서이다.)\
![Queue2](../image/1.1%20Queue2.PNG)

+ Linked Queue\
LinkedList를 이용해서 만든 큐이다.\
오버플로우가 발생하지 않는 것이 특징이다.

![Queue3](../image/1.1%20Queue3.jpg)

+ 활용 예시
1. 인쇄기 대기열같은 일반적인 대기줄 / 대기열에 사용된다.
2. DFS(너비우선탐색) 알고리즘에서 사용된다.

#### 생각해보기
+ Stack 을 사용하여 미로찾기 구현하기
+ Queue 를 사용하여 Heap 자료구조 구현하기
+ Stack 두 개로 Queue 자료구조 구현하기
+ Stack 으로 괄호 유효성 체크 코드 구현하기

## Graph

+ 정의

노드(node)와 그 노드를 연결하는 간선(edge)의 집합을 의미한다.\
**네트워크 모델**을 만들기 위해서 사용되었다고 한다. (실재로 그래프와 관련된 문제는 네트워크를 주제로 했던 문제가 많았던 것 같다.)

+ 용어

1. 노드(node) / 버텍스(vertex) : 그래프 상의 특정 위치나 점을 의미
2. 간선(edge, link, branch) : 노드와 노드를 잇는 선을 의미 <img src="../image/1.1%20Graph1.PNG" width="5%" height="5%">
3. 자체 간선(self-loops) : 자신에서 시작하여 자신으로 들어오는 간선
3. 가중치(weight) : 간선에 부여된 비용, 시간, 중요도 등을 의미한다. 언급이 없다면 모든 간선의 가중치가 같다고 생각한다.
3. 인접(adjacent) : 정점 u, v가 있고 이 두 정점을 잇는 간선 e가 있다고 가정할 때 정점 u, v는 e로 인해 서로 인접한다고 말한다.. 
3. 부속(incident) : 위와 같은 상황에서 간선 e는 정점 u, v에 부속한다고 말한다.
4. 차수(degree) : 무향 그래프에서 하나의 노드에 연결되어있는 간선의 수
5. in-degree : 방향 그래프에서 노드로 들어오는 간선의 수
6. out-degree : 방향 그래프에서 노드에서 나가는 간선의 수
7. 경로(path) : 노드 a에서 노드 b로 가는 과정을 의미한다. 여러 개가 존재할 수 있으며 아예 없을 수도 있다.
8. 경로 길이(path length) : 경로를 구성하는 데 사용된 간선의 수
9. 사이클(cycle, 순환) : 시작 정점과 종료 정점이 동일한 경우
10. 단순 경로(simple path) : 사이클을 구성하는 노드가 시작 노드와 마지막 노드를 제외하고 중복이 없는 경우
11. 비순환(acycle) : 사이클이 아닌 경우

+ 종류

1. 유향 그래프(Directed graph) / 무향 그래프(Undirected graph)\
간선에 방향성이 있는 그래프 / 간선에 방향성이 없는 그래프, 양방향 유향그래프라고 생각해도 무방하다.
2. 가중치 그래프(Weighted graph)\
각 간선에 가중치가 부여된 그래프
4. 완전 그래프(Complete graph)\
각 노드가 자신을 제외한 모든 노드에 연결된 그래프
5. 밀집 그래프(Dense graph) / 희소 그래프(Sparse graph)\
노드의 수보다 간선의 수가 많은 그래프 / 노드의 수보다 간선의 수가 적은 그래프
5. 순환 그래프(Cycle graph) / 비순환 그래프(Acycle graph)\
사이클인 경로가 하나라도 있는 그래프 / 사이클인 경로가 하나도 없는 그래프
7. **트리(Tree)**\
순환 그래프가 아닌 유향 그래프
8. 연결 그래프(Connected graph) / 비연결 그래프(Disconnected graph)\
무방향 그래프에 있는 모든 정점쌍에 대해서 항상 경로가 존재하는 경우 / 특정 정점쌍 하나라도 경로가 존재하지 않는 경우

+ 특징 (트리와의 차이점)
1. 그래프는 **네트워크 모델**이다.
2. 2개 이상의 경로가 가능하다.
3. self-loop와 사이클이 있을 수 있다.
4. 루트 노드라는 개념이 없다.
5. 부모-자식 관계라는 개념이 없다.
6. 순회는 DFS나 BFS로 이루어진다.
7. 그래프는 순환(Cyclic) 혹은 비순환(Acyclic) 둘 중 하나이다.
8. 노드에 간선이 있을수도 없을수도 있다.

### 그래프 표현 방법

#### 인접 행렬(adjacent matrix) - 행렬(2차원 배열)을 사용
NxN BooleanMatrix(일반적으로 2차원 배열로 구현)을 만든 뒤 행렬에 간선의 유무를 적어놓는 방식이다.

간선의 유무는 O(1)로 파악할 수 있지만\
특정 노드에서 인접한 모든 노드를 찾는 속도는 O(V)로 느린편이다.
공간 복잡도는 V^2이다.\
Dense graph를 표현할 때 좋다.
> <img src="../image/1.1%20Graph7.png" width="35%" height="35%">

#### 인접 리스트(adjacent list) - 연결 리스트 사용
배열(혹은 해시테이블)과 배열의 각 인덱스마다 존재하는 또 다른 리스트(Array, ArrayList, 연결리스트(LinkedList) 등)를 이용하여 표현한다.\
그래프를 표현하는 일반적인 방법이다. 위에서 그래프의 가본이 되는 자료형이 LinkedList라고 했던 이유이다.

간선의 유무는 *관련된 노드의 차수만큼의 시간*으로 파악할 수 있고\
특정 노드에 인접한 모든 노드를 찾는 속도 위와 같으며 이것은 행렬에 비해서 상대적으로 빠르다. 애초에 인접한 노드들만 저장을 했기 때문이다.\
각 노드와 관계가 있는 간선만을 저장하므로 공간 복잡도는 V+E이다.\
Sparse graph를 표현할 때 좋다.
> <img src="../image/1.1%20Graph6.png" width="40%" height="40%">

+ 무/유향 그래프에서의 그래프 표현

<img src="../image/1.1%20Graph2.PNG" width="40%" height="40%"> <img src="../image/1.1%20Graph3.PNG" width="40%" height="40%">

+ 가중 무/유향 그래프에서의 그래프 표현

<img src="../image/1.1%20Graph4.PNG" width="40%" height="40%"> <img src="../image/1.1%20Graph5.PNG" width="40%" height="40%">

### 그래프 탐색
그래프는 기본적으로 노드와 간선에 대한 순서나 규칙이 없다.\
때문에 그래프를 탐색할 때에는 모든 노드를 살펴야 하는 경우가 매우 많은데 그 방법은 아래의 두 알고리즘을 기반으로 한다.

#### 깊이 우선 탐색(Depth First Search: DFS)
글로 설명하기 어려우니 그냥 그림을 보자..\
stack을 사용하여 구현한다.\
시간 복잡도는 모든 노드와 간선을 조사하므로 O(V+E)이다.\
공간 복잡도는 각 노드에 방문 여부를 채크할 변수 크기 즉, O(V)이다.

<img src="../image/1.1%20Graph8.PNG" width="40%" height="40%"> <img src="../image/1.1%20Graph9.PNG" width="40%" height="40%">

#### 너비 우선 탐색(Breadth First Search: BFS)
마찬가지로 글로는 어렵다 그림을 보자..
깊이우선탐색과 마찬가지의 이유로 시간 복잡도는 O(V+E),\
공간 복잡도는 O(V)이다.

시작 노드와 목표로 하는 노드를 정하고 시작 노드부터 너비 우선 탐색을 진행하였을 때\
**너비 우선 탐색을 적용하여 찾은 두 노드의 경로는 항상 최단거리이다.**

<img src="../image/1.1%20Graph10.PNG" width="40%" height="40%">

### 최소 신장 트리 (Minimum Spanning Tree)
그래프가 가진 간선의 일부 혹은 전체를 이용하여 그 그래프의 모든 노드를 잇는 트리(비순환 유향 그래프)를 <code>신장 트리(Spanning Tree)</code>라고 한다.\
가중치 그래프에서 **만들 수 있는 신장 트리 중 사용한 간선의 가중치 합이 가장 적은 것**를 최소 신장 트리라고 한다.\
간선의 가중치가 이 최소 신장 트리를 만드는 알고리즘은 대표적으로 2개가 있는데 아래와 같다.

#### Prim Algorithm
그래프에서 만들 수 있는 작은 트리를 점차 확장시켜 결국에는 최소 신장 트리를 만드는 방법

+ 동작 방식
1. 시작 노드를 MST(최소 비용 신장 트리) 집합에 넣는다. (시작 노드는 그래프내 어떤 노드라도 상관없다.)
2. MST 집합에 있는 노드와 연결된 간선 중 (이미 사용한 간선을 제외하고) 가장 가중치가 작은 값을 가지는 간선을 골라 이어준 후 MST의 원소로 추가한다.
3. MST가 완성될 때까지 2번을 반복한다.

+ 특징
1. 인접행렬로 구현시 시간 복잡도 O(V^2)를 가지고 힙을 사용하면 O(E log V)의 시간 복잡도를 가진다.\
2. Dense graph에서 유리하다.

+ 예시 사진
<img src="../image/1.1%20Graph11.PNG" width="45%" height="60%">
<img src="../image/1.1%20Graph12.PNG" width="60%" height="60%">

#### Kruskal Algorithm
탐욕법(Greedy) 알고리즘을 기본으로 하면서 사이클이 만들어 지지 않도록 조건을 두어 간선을 선택해 나가는 방법\
원래 탐욕법은 당장에는 최적이지만, 전체적인 관점에서 최적이라는 보장이 없기 때문에 반드시 검증해야 한다.\
다행히 Kruskal 알고리즘은 최적의 해답을 주는 것으로 증명되어 있다.\

+ 동작 방식
1. 그래프의 모든 간선들을 가중치의 오름차순으로 정렬한다.
2. 그래프의 각 노드에 번호(id)를 부여한다. 이는 각 노드의 그룹에 대한 정보이다.
3. 정렬된 간선을 차례로 보면서 해당 간선을 추가 했을 때 양 노드의 그룹 정보를 Disjoint-set 알고리즘으로 확인하여 사이클 여부를 확인한다.
4. 두 노드가 같지 않은 그룹(사이클 생성이 안되면)이면 Disjoint-set의 병합과정을 거쳐 두 그룹을 합친다.
5. 같은 그룹이라면 다음 간선을 선택한다.
6. 간선의 개수가 '노드의 개수 - 1'이 될 때까지 2~5를 반복한다.

+ 특징
1. 시간복잡도는 O(E log V) 혹은 O(E log E)이다. (위키백과에 쓰여있지만 증명이 너무 어려워서 외우기만..)
2. Sparse Graph에서 유리하다.

+ 예시 사진
<img src="../image/1.1%20Graph13.PNG" width="70%" height="70%">

+ 참고
  + https://www.codeground.org/common/popCodegroundNote

### 최단 경로

#### Dijkstra Algorithm (다익스트라 알고리즘)
**음의 가중치가 없는 그래프에서 사용해야한다**는 조건이 있다.\
한 노드에서 다른 모든 노드까지의 최단거리를 구하는 알고리즘이다.

+ 구현 방법
0. 배열의 A번째 값을 d[A]라고 하고 A와 B사이의 간선을 P[i][j]라고 하겠다.
1. 최단거리를 저장할 배열을 만든다. 시작 노드의 배열 값은 0을, 그 외에는 매우 큰 값을 넣어 초기화한다.
2. 배열에서 이미 **탐색한 노드**를 제외하고 가장 작은 값을 가지는 노드를 가져온다.\
  가장 작은 값을 가지는 노드는 힙(을 활용해서 만든 우선순위 큐)이나 배열을 이용해서 구한다.
3. 가져온 노드를 A라고 하고 A와 인접한 노드를 B라고 할 때, d[B]와 d[A]+P[A][B]를 비교해서 더 작은 값을 d[B]에 넣는다.\
  A의 모든 이웃 노드 B에 대해 이 작업을 수행한다.
4. A의 상태를 **탐색한 노드**로 바꾼다.
5. 목표 노드가 "방문 완료" 상태가 되거나 더 이상 미방문 상태의 노드를 선택할 수 없을 때까지 2~4의 과정을 반복한다.

+ 특징
1. 가장 작은 값을 가진 노드를 가져올 때\
인접행렬로 구현시 시간 복잡도 O(V^2)를 가지고 (최대)힙(Heap)을 활용하면 O((V+E)logV)의 시간 복잡도를 가진다.

선택한 노드를 힙에 넣고 정렬하는데 O(logV), 노드마다 한번씩은 힙에 들어가므로 O(V) => O(VlogV)의 시간에
각 노드마다 이웃한 노드의 최단 거리를 탐색하고 O(E), 그 정보를 갱신하기 위해 힙을 탐색하는데 O(logV)가 필요하므로 => O(ElogV)
즉, O((E+V)logV)가 필요하다.

2. 시작 노드에서 목표 노드까지의 최단거리를 구하는 과정에서 시작 노드와 그 외의 노드 간의 최단거리까지 구해버린다.

+ 예시 사진

<img src="../image/1.1%20Graph14.gif" width="40%" height="40%">
~~마지막에 노드 4의 값(20)과 '5-4 간선+노드 5의 값'(26)을 비교해야 할 것 같은데 안하는 것으로 보아 목표노드가 5인것 같다.~~

+ 활용 예시
1. 네비게이션 길찾기
2. 지하철 최단거리
3. 네트워크 경로찾기

#### Bellman-Ford Algorithm (벨만-포드 알고리즘)
**음의 가중치가 있는 그래프에서도 사용이 가능**하다. 단, **음의 사이클이 없어야** 한다.\
기능은 위의 다익스트라 알고리즘과 같다.

+ 동작 방식
0. 배열의 A번째 값을 d[A]라고 하고 A와 B사이의 간선을 P[i][j]라고 하겠다.
1. 다익스트라와 같이 최단거리를 저장할 배열을 만든다. 시작 노드의 배열 값은 0을, 그 외에는 매우 큰 값을 넣어 초기화한다.
2. 간선이 노드A와 B를 잇는다고 할 때, d[B]와 d[A]+P[A][B]를 비교해서 더 작은 값을 d[B]에 넣는다.\
  모든 간선에 대하여 위의 작업을 해준다.
3. 2번의 작업을 V번 해준다.
4. 만약 V번째에도 갱신이 되는 노드가 있다면 음수 사이클이 있다는 의미이다. (음수 사이클이 없다면 N-1내에 모든 노드가 최단 경로를 가진다.)

+ 특징
1. 시간복잡도는 O(EV)이다. 모든 간선을 V번 살펴보기 때문이다.
1. 다익스트라 알고리즘보다 느리다.
2. 음수 가중치가 있는 그래프에서도 사용 가능하다.
3. 음수 사이클이 존재하는지 판별이 가능하다.

+ 예시 사진

order에 적힌 순서로 간선을 탐색한다.

<img src="../image/1.1%20Graph15.png" width="60%" height="60%">
<img src="../image/1.1%20Graph16.png" width="60%" height="60%">

#### Floyd-Warshall Algorithm (플로이드-워셜 알고리즘)
**음의 가중치가 있는 그래프**에서 **모든 노드에서 다른 모든 노드까지의 최단 경로**를 구하기 위해 고안되었다.
코딩은 쉬운데 무슨 말인지 내가 아직 이해를 못했다..

+ 동작 방식
모든 정점쌍 (i,j)에 대하여 k라는 경유지를 거쳤을 때, 기존의 정점쌍의 거리보다 짧아진다면, 정점쌍의 최단거리를 갱신시켜준다.\
모든 최단거리는 음수 사이클이 없다면, 그 경로의 길이는 당연히 N이하가 되고 이를 이용해 동적계획법으로 해결 가능하다.\
..는데 잘 모르겠다. 그림을 봐도 모르겠다..

+ 특징
1. 시간복잡도는 O(V^3)이다.
2. 음수 가중치가 있는 그래프에서 사용 가능하다.

+ 경로 종류별 사용 알고리즘
  + 시작 노드 하나, 도착 노드 하나 - Dijkstra 알고리즘, Bellman-Ford 알고리즘 
  + 시작 노드 하나, 도착 노드 전체 - 위와 동문
  + 시작 노드 전체, 도착 노드 하나 - 그래프의 에지 방향을 모두 반대로 바꾸면 시작 노드 하나, 도착 노드 전체 문제로 바뀐다.
  + 시작 노드 전체, 도착 노드 전체 - Dijkstra 알고리즘, Bellman-Ford 알고리즘의 도착/시작 노드를 모든 노드에 적용한다. 혹은 Floyd-Warshall Algorithm 사용

## Tree
순환 그래프가 아닌 유향 그래프들을 모두 트리라고 한다.\
기본적으로 그래프이기 때문에 배열과 링크드 리스트로 구현이 가능하다.\
계층적 관계를 나타내는 모델을 위해서 만들어졌다. ex) 디렉터리 구조, 구조도

+ 용어
  + Node (노드) : 트리를 구성하고 있는 각각의 요소
  + Edge (간선) : 트리를 구성하기 위해 노드와 노드를 연결하는 선
  + level (레벨) : 루트에서 자신에게 걸리는 거리, 루트 노드의 레벨은 1이다.
  + Depth (깊이) : 루트 노드에서 특정 노드까지 사용되는 간선의 최소 수, 루트노드의 깊이는 0 이다.
  + Height (높이) : 트리의 가장 높은 레벨(Level)
  + Parent (부모) : 특정 노드보다 레벨이 낮으면서 간선으로 연결되어있는 노드
  + Son (자식) : 특정 노드보다 레벨이 높으면서 간선으로 연결되어있는 노드
  + Sibling (형제) : 같은 부모를 갖는 노드
  + Ancestors (조상) : 루트 노드에서 특정 노드까지 갈 때, 경로에 있는 모든 노드
  + Descendant(후손): 특정 노드에서 갈 수 있는 모든 노드
  + Degree (차수) : 특정 노드의 자식 수
  + 트리의 차수: 트리의 모든 노드 중에 가장 높은 차수
  + Root Node (루트 노드) : 트리 구조에서 최상위에 있는 노드, 유일하게 부모가 없는 노드
  + Terminal Node (=leaf Node, 단말 노드) : 차수가 0인(자식이 없는) 노드, 단말(Terminal) 혹은 잎(Leaf)이라고 부른다.
  + Internal Node (내부노드, 비단말 노드) : 단말 노드를 제외한 모든 노드 (루트 노드를 포함)
  
  <img src="../image/1.1%20Graph17.PNG" width="50%" height="50%">
  
+ 특징
  + 트리는 계층 모델이다.
  + 사이클이 존재하지 않는 유향 그래프이다.
  + 트리에는 하나의 루트 노드만이 존재하고 모든 자식 노드는 한 개의 부모 노드만이 있다.
  + 임의의 두 노드 간의 경로가 유일하다. 반드시 1개의 경로만을 가진다.
  + 간선의 수는 항상 트리에 있는 노드의 수의 + 1 이다.
  
+ 종류
  + Binary Tree (이진 트리) : 트리 내의 모든 노드의 차수가 2 이하인 트리, 아래에 자세하게 서술하였다.
  + B-Tree : 이진 트리를 확장하여 하나의 노드가 가질 수 있는 자식 노드의 최대 숫자가 2보다 큰 트리
  + Forest (포레스트)
  + Trie (트라이) : 각 노드에 문자를 저장하여 접두사를 빠르게 찾기 위한 트리
  + Balanced Tree (균형 트리) : 단말 노드가 가능한 한 최소 높이를 가지는 트리
  + Sub Tree (서브 트리) : 하나의 노드와 그 노드의 후손들로 이루어진 트리
  + Skewed Binary Tree (편향 트리) : 한쪽으로 기울어진 트리
  
  (왼쪽은 서브트리 사진, 오른쪽은 균형/비균형 이진 트리의 사진)
  
  <img src="../image/1.1%20Graph23.jpg" width="40%" height="40%">
  <img src="../image/1.1%20Graph24.png" width="40%" height="40%">

+ 구현 방법 참고
  + https://gmlwjd9405.github.io/2018/08/12/data-structure-tree.html

### Binary Tree
모든 노드의 최대 자식 수가 2인 트리

+ 순회\
부모 노드의 방문 순서에 따라서 이름이 바뀐다. 또한 왼쪽 자식 노드을 오른쪽 자식 노드보다 항상 먼저 방문하도록 한다.
  + 전위 순회 (In-order traversal) : 왼쪽 자손 노드 - 부모 노드 - 오른쪽 자손 순서로 방문
  + 중위 순회 (Pre-order traversal) : 부모 노드 - 왼쪽 자손 노드 -  오른쪽 자손 노드 순서로 방문
  + 후위 순회 (Post-order traversal) : 왼쪽 자손 노드 - 오른쪽 자손 노드 - 부모 노드 순서로 방문
  + 레벨 순서 순회(Level-order traversal): 너비 우선 순회(Breadth-First traversal)라고도 한다. 노드를 레벨 순서로 방문하는 순회 방법.
  
<img src="../image/1.1%20Graph18.PNG" width="40%" height="40%">

      레벨 순서 순회는 큐로 구현이 가능하고 나머지는 모두 스택으로 구현이 가능하다.

+ 종류\
트리 용어는 잘 표준화되어 있지 않아서 문헌마다 차이가 있다. 나는 위키백과를 기준으로 서술할 것이다.
  + Full Binary Tree (전 이진 트리) : 모든 노드가 0개 또는 2개의 자식 노드를 갖는 트리
  + Complete Binary Tree (완전 이진 트리) : 마지막 높이를 제외한 모든 높이에서 노드가 꽉 차 있는 이진 트리, 마지막 높이의 노드는 모두 채워져 있지 않아도 되는 대신 왼쪽에서 오른쪽으로 빠짐없이 채워져야 한다.
    + Heap Tree (힙 트리) :  보통 '힙'이라고 줄여 부르며 최대값(최소값)을 빠르게 찾기 위해 만들어졌다.
  + Perfect Binary Tree (포화 이진 트리) : 모든 리프 노드의 높이가 같은 트리
  + Binary Search Tree (이진 탐색 트리) : 모든 노드가 아래의 조건에 충족하는 트리\
    "왼쪽 자식 노드의 데이터 값 <= 부모 노드의 데이터 값 < 오른쪽 자식 노드의 데이터 값"
    
  <img src="../image/1.1%20Graph19.PNG" width="50%" height="50%">
  
### Heap
**완전 이진 트리 종류 중 하나**로 Priority Queue(우선순위 큐)를 위해서 만들어진 자료구조이다.
이를 위하여 부모와 자식 간의 데이터 값에 조건이 있으며 이 조건을 충족시키기 위해서 **heap의 구조를 유지하는 것을 heapify**라고 한다.

+ 구현 방법
  0. 일반적으로 (완전 이진 트리는) 배열로 구현하므로 배열을 사용한다는 전제가 있다.
  1. 인덱스 0은 비운 채로 1부터 노드의 데이터 값을 넣는다. (0부터 채워도 된다.)
  2. 부모와 자식 간의 노드의 인덱스에는 다음과 같은 관계가 있다. heapify를 할 때 아래의 관계를 참고하여 구현한다.
    + 왼쪽 자식의 인덱스 = (부모의 인덱스) * 2 (인덱스 0을 채울 경우 왼쪽 자식의 인덱스 = (부모의 인덱스) * 2 + 1)
    + 오른쪽 자식의 인덱스 = (부모의 인덱스) * 2 + 1 (인덱스 0을 채울 경우 오른쪽 자식의 인덱스 = (부모의 인덱스) * 2 + 2)
    + 부모의 인덱스 = (자식의 인덱스) / 2 (인덱스 0을 채울 경우 부모의 인덱스 = (자식의 인덱스 - 1)를 2로 나눴을 때의 )
    
     > <img src="../image/1.1%20Graph20.png" width="60%" height="60%">

+ heapify 과정 
  1. 노드를 삽입 했을 때 (최대 힙 기준)
  
  > <img src="../image/1.1%20Graph21.png" width="60%" height="60%">
  
  2. 노드를 삭제 했을 때 (최대 힙 기준)
  
  > <img src="../image/1.1%20Graph22.png" width="60%" height="60%">

+ 특징
  + 중복된 값을 허용한다. (이진 탐색 트리에서는 중복된 값을 허용하지 않는다.)
  + 값을 모두 정렬하지 않는다. 단지, 가장 큰(작은) 값만 빠르게 찾을 뿐이다.
  + 최댓값이나 최솟값을 찾는데 O(1)의 시간 복잡도로 아주 빠른 편이다.
  + 노드가 삭제되거나 삽입되면 heapify 과정이 필요한데 이는 O(log n)이 걸린다.

+ 종류
  + Max Heap (최대 힙) : 부모 노드가 자식노드보다 크거나 같은 값을 가지는 조건을 가진 완전 이진 트리
  + Min Heap (최소 힙) : 부모 노드가 자식노드보다 작거나 같은 값을 가지는 조건을 가진 완전 이진 트리

### BST - Binary Search Tree (이진 탐색 트리)
데이터를 효율적으로 탐색하기 위해서 데이터를 저장하는 규칙이 있는 트리이다.\
탐색이 Worst Case에 걸리지 않도록 하기 위해서 Rebalancing 기법이 사용되기도 하며 이러한 알고리즘을 가진 트리를 <code>자가균형 이진탐색트리</code> 라고 한다.
기본적으로 이진 트리의 모양을 가지고 있으며 다음과 같은 규칙이 있다.\

+ 규칙
1. 이진 탐색 트리의 노드에 저장된 키는 유일하다.
2. 루트 노드의 키가 왼쪽 서브 트리를 구성하는 어떠한 노드의 키보다 크다.
3. 루트 노드의 키가 오른쪽 서브 트리를 구성하는 어떠한 노드의 키보다 작다.
4. 왼쪽과 오른쪽 서브트리도 이진 탐색 트리이다.

+ 특징
  + 데이터 값의 중복이 허용되지 않는다.
  + 중위 순회를 하면 작은 값에서 큰 값 순으로 데이터를 방문할 수 있다.
  + 탐색 연산에 O(lon n)(사실은 O(h))의 시간 복잡도가 필요하다.
  + 데이터가 한쪽으로만 몰린 편향 트리가 될 수 있다. 이 경우 Worst Case가 되며 시간 복잡도는 O(n)이 된다.

+ 종류
  + 자가균형 이진탐색트리 : 이름 그대로 스스로 균형 트리가 되도록 만드는 이진 탐색 트리, 이상적인 상황에서나 최악의 상황에서 탐색/삽입/삭제 모두 시간 복잡도가 O(log N)인 것이 특징이다.
    + AVL Tree : 가장 처음으로 나온 자가 균형 이진 탐색 트리, 아래의 트리와 비교하여 삽입과 제거가 느리고 탐색 자체는 빠르다.
    + Red-Black Tree : 노드에 색깔 속성이 붙은 트리, 구현은 꽤나 복잡하지만 현실에선 매우 효율적인 방법이기 때문에 자가균형 이진탐색트리를 만든다면 이것이 자주 쓰인다.

### Red-Black Tree - RBT
BST를 기반으로 하는 트리이다.\
위에서 서술한 대로 트리의 높이를 최소화하여 시간 복잡도를 줄이는 것이 핵심인 트리이다.\
상당히 규칙이 많아서 구현하기 복잡한데 그 규칙을 아래에 서술한다.

+ 규칙
0. 노드의 자손이 없을 경우 자손를 가리키는 포인터는 널(NULL)값을 저장한다. 이 널값들을 단말 노드로 간주한다.
1. 노드는 Red or Black이라는 색깔을 갖는다.
2. 루트 노드의 색깔은 Black이다.
3. 모든 단말 노드의 색은 black이다.
4. 어떤 노드의 색깔이 red라면 그 노드의 자식 노드 색은 모두 black 이다. (red 색을 가지는 노드는 연속으로 존재할 수 없다.)
5. 임의의 한 노드에서 단말 노드까지의 모든 경로에는 단말 노드를 제외하고 항상 같은 수의 블랙 노드가 있다.\
이 수를 Black-Height라고 한다.

+ 특징
  + 이진 탐색 트리와 균형 트리의 특징을 모두 가지고 있다.
  + 이상적인 상황에서나 최악의 상황에서 탐색/삽입/삭제 모두 시간 복잡도가 O(log N)이다.
  
#### 삽입 구현 방법
삽입하는 노드의 색을 Red로 지정(Black-Height에 영향을 끼치지 않으므로)하고 우선 BST의 조건을 지키면서 노드를 넣는다.\
Black-Height 조건에 맞지않으면 rotation(트리 회전이라고 불린다.)을 통해 height 를 조정하고 연속으로 Red 노드가 있다면 색을 조정한다.

Case 1이 Black-Height 조건에 맞지 않았을 때 / Case 2가 연속으로 Red인 노드가 있을 때 조정하는 방법이다.\
대문자들은 A<B<C인 조건을 가지는 내부 노드이고 소문자들은 단말 노드(NULL)을 나타낸다.\
가장 아래의 Red 노드가 삽입된 상태에서 조정하면 왼쪽과 같은 트리가 된다.

<img src="../image/1.1%20Graph25.png" width="40%" height="40%"> <img src="../image/1.1%20Graph26.png" width="40%" height="40%">

#### 삭제 구현 방법
설명이 잘 되어있는 곳을 못 찾았다.\
스스로 생각해서 도출해도 되지만 지금은 시간이 너무 없어서 생략한다.

## HashTable (해시 테이블)
HashTable 또는 HashMap이라고 불린다.\
연관배열 구조를 이용하여 키(key)를 알고있으면 대응하는 값(value)을 빠르게 찾을 수 있는 자료구조이다.\
키는 임의의 길이를 가지는 데이터이므로 그대로 사용하면 저장할 공간이 낭비되므로 고정된 길이를 가지는 해시값으로 바꿔준다.

+ 용어
  + Key (키) : 임의의 길이를 갖는 데이터이며 중복이 불가능하다.
  + Value (값) : 키와 매칭되어 저장되는 데이터를 의미한다.
  + 연관배열 구조 (Associative Array) : 키(key) 데이터와 값(value) 데이터가 1:1로 연관되어 있는 자료구조이다. 다음과 같은 기능이 있다.
    + 키(key)와 값(value)이 주어졌을 때, 연관 배열에 그 두 값(key & value)을 저장한다.
    + 키(key)가 주어졌을 때, 연관되는 값(value)을 얻을 수 있다.
    + 키(key)와 새로운 값(value)이 주어졌을 때, 원래 키에 연관된 값(value)을 새로운 값(value)으로 교체할 수 있다.
    + 키(key)가 주어졌을 때, 그 키(key)에 연관된 값(value)을 제거할 수 있다.
  + Hash Function (해시함수) : 키를 입력으로 받아서 해시값을 반환한다.\
  입력되는 데이터의 범위보다 출력되는 데이터의 범위가 좁다는 특징이 있으며 이 때문에 서로 다른 키에서 값은 해시값이 나올 수 있다. 
  + Hash (해시값) : 해시 함수에서 나온 결과 값이다. 값들은 고정된 길이를 가지게 되며 저장소의 위치를 의미한다.\
  해시 코드(hash code), 해시섬(hash sum), 체크섬(check sum) 등으로도 불린다.
  + Bucket (=Slot, 버킷) : 값(value)이 저장되는 곳이다.
  + Collision (충돌) : 해시 함수에서 다른 키로 같은 해시값이 생성되어 이미 사용하고 있는 저장소 위치에 접근하는 상황을 해시 충돌이라고 한다.
  
  <img src="../image/1.1%20Graph29.png" width="50%" height="50%">

### 좋은 Hash Function 조건
1. 키(key)에 대응하는 값(value)은 1:1 대응이 **아닌 것**이 좋다.\
현실적으로 불가능하기도 하지만 메모리도 많이 소비하며 차라리 그냥 배열을 사용하는 것이 좋다.
2. Collision이 적을 수록 좋다.\
충돌이 많아질 수록 시간 복잡도가 O(1)에서 O(n)에 가까워지기 때문이다.

      즉, 해시 테이블은 충돌이 불가피하며 충돌을 적게하는 함수를 선택하고 충돌을 해결하는 방법을 아는 것이 중요하다.

### Collision Resolution
충돌을 해결하기 위한 다양한 방법이 있지만 기본적으로 크게 두 가지 방식으로 충돌 해결법을 나눌 수 있다.

#### 1. Open Address (개방 주소법)
공개 주소 방식이라고도 불린다.\
충돌이 일어난 경우 다른 비어있는 버킷에 자료를 넣는 방법이다.\
Worst Case라면 슬프게도 빈 공간을 찾지 못하고 원래자리로 돌아올 수 있다.\
대표적으로 3가지 종류가 있는데 다음과 같다.

1. Linear Probing (선형 탐색)\
순차적으로 비어있는 버킷을 찾을 때까지 계속 탐색한다.\
처음 탐색한 위치를 f(k)이라고 하면 다음과 같이 탐색한다.\
 f(k) + 1 -> f(k) + 2 -> f(k) + 3 -> ...
 
 <img src="../image/1.1%20Graph27.png" width="50%" height="650%">

2. Quadratic probing (제곱 탐색)\
순차적으로 탐색하지 않고 제곱한 값을 더하면서 탐색한다.\
처음 탐색한 위치를 f(k)이라고 하면 다음과 같이 탐색한다.\
f(k) + 1² -> f(k) + 2² -> f(k) + 3² -> ...

3. Double hashing probing (이중 탐색)\
해쉬 함수에서 충돌이 발생하면 다른 해쉬 함수를 이용해 새로운 주소를 할당한다. 위 두 가지 방법에 비해 많은 연산량을 요구하게 된다.

+ 특징
  + 해시테이블 자체에서 데이터 저장 및 처리가 가능하다.
  + 해시 함수의 성능이 전체 해시테이블의 성능을 좌지우지한다.
  + 저장소가 늘어나지 않는 이상 저장할 수 있는 데이터 양도 한정되어있다.
  + 삽입/삭제/탐색 모두 최상의 경우 O(1), 최악의 경우 O(n)의 시간 복잡도를 가진다.

#### 2. Separate Chaining (분리 연결법)
줄여서 체이닝(Chaining)이라고 하기도 하며 일반적으로 Open Address 보다 Separate Chaining이 더 빠르다.\
Open Address 의 경우 빈 버킷을 적어질수록 Worst Case 발생 빈도가 더 높아지기 때문이다.\
동일한 해쉬 값에 대해 여러 값을 저장하여 충돌을 해결하는 방법이다.\
링크드 리스트나 트리를 사용하여 구현할 수 있다.

1. 연결 리스트를 사용하는 방식 (Linked List)\
각 버킷을 연결리스트(Linked List)로 만들어 Collision 이 발생하면 해당 버킷의 연결리스트에 추가하는 방식이다.\
버킷을 그대로 사용하는 Open Address 방식에 비해 테이블의 확장을 늦출 수 있다.\

2. 트리를 이용하는 방식 (Red-Black Tree)
위와 같은 방식으로 동작하지만 연결 리스트 대신에 트리를 사용하는 방법\
한 버킷에 저장된 데이터 수가 많을수록 위의 방법보다 효율적이다.\
반대로 데이터 수가 적다면 연결 리스트를 사용하는 것이 메모리를 절약할 수 있다.

<img src="../image/1.1%20Graph28.png" width="60%" height="60%">

+ 특징
  + 한 버킷에 여러 데이터가 저장될 수 있어 한정된 해시 테이블에서 더 많은 데이터를 저장할 수 있다.
  + 연결 리스트의 특성과 같이 데이터의 크기가 동적이다.
  + 해시 함수를 선택하는 중요성이 상대적으로 적다.
  + 한 버킷에만 데이터가 몰리면 성능이 저하된다.
  + 추가적인 저장공간(연결리스트)를 사용하므로 추가적인 연산이 필요하다.
  + 1개의 Bucket당 평균적으로 a개의 데이터가 들어있다고 할 때\
    + head에 삽입할 때에는 O(1), tail에 삽입할 때에는 BestCase O(a)/ WorstCase O(n)의 시간 복잡도를 가진다. 
    + 탐색/삭제는 BestCase O(a), WorstCase O(n)의 시간 복잡도를 가진다.
  
+ 기타
  + 보조 해시 함수 :  Separate Chaining 방식을 사용할 때, 해시값을 변형하여 해시 충돌 가능성을 줄이는 것이다.
  + load factor : 해시 버킷의 수가 저장하는 데이터 수에 비해서 적어서 충돌이 많이 일어난다면 해시 버킷의 수를 증가시키면 되는데 그러한 임계점을 의미한다. \
  예를들어서 100개의 버킷이 있는 해시 테이블에서 75개의 버킷이 사용될때 해시 버킷을 동적 확장한다고 하면 load factor는 0.75이다.
  
+ 참조
  + https://velog.io/@cyranocoding/Hash-Hashing-Hash-Table%ED%95%B4%EC%8B%9C-%ED%95%B4%EC%8B%B1-%ED%95%B4%EC%8B%9C%ED%85%8C%EC%9D%B4%EB%B8%94-%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0%EC%9D%98-%EC%9D%B4%ED%95%B4-6ijyonph6o
