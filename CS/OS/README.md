# 1-3. 컴퓨터 구조와 운영체제

+ OS란?
+ 프로세스
  + 메모리 영역
  + 상태 주기
  + PCB(Process Control Block)
+ 쓰레드
  + 멀티 프로세스와 멀티 쓰레드
+ 프로세스/쓰레드 동기화
  + Critical Section(임계영역)
    + 락(Lock)
    + 세마포어(Semaphores)
    + 교착상태(DeadLock)
+ CPU 스캐줄링
  + 장기스케줄러(Long-term scheduler)
  + 중기스케줄러(Medium-term scheduler)
  + 단기스케줄러(Short-term scheduler)
    + FCFS(First Come First Served)
    + SJF(Shortest Job First) & SRTF(Shortest Remaining time First)
    +  Round Robin
+ 메모리 관리
  + Paging(페이징)
  + Segmentation(세그멘테이션)
  
</br>

아래의 내용은 조성호 저자의 `쉽게 배우는 운영체제` 책과 위키백과의 내용, 블로그 글을 참고하여 작성되었음을 밝힌다.   
(블로그 글들의 내용을 참고하여 작성했던 글들을 검증하기 위해 책을 사서 읽고 내용을 고쳐나가는 중이다.)

## OS란?

사용자에게 편리한 인터페이스 환경을 제공하고 응용 프로그램과 사용자에게 컴퓨터 시스템의 자원을 효율적으로 관리하는 시스템 소프트웨어   
대표적으로 마이크로소프트 윈도우, 맥 OS, 리눅스, 안드로이드(모바일 운영체제), 임베디드 운영체제(스마트 시계나 TV에 사용)가 있다.

운영체제의 역할을 간략하게 작성하면 아래와 같다.
1. 사용자와 하드웨어 사이에서 중재자 역할을 하며 사용자나 응용 프로그램의 요청에 따라 자원을 관리한다. (효율성)
2. 자원의 효율적인 분배로 컴퓨터의 성능을 향상시킨다. (효율성)
3. 사용자에게 편리한 인터페이스 환경을 제공하여 사용자의 요청에 대한 결과를 보여준다. (편리성)
4. 악의적인 응용 프로그램으로부터 자원을 보호한다. (안전성)
5. 다양한 하드웨어를 지원한다. (확장성)

#### 운영체제가 사용자나 응용프로그램이 직접 컴퓨터 자원을 사용하는 것을 막는 이유

그 이유가 악의적인 프로그램이나 미숙한 사용자가 다른 사용자의 작업 데이터를 덮어 씌우거나 삭제하여 문제를 일으킬 수 있기 때문이다.

#### 하드웨어 인터페이스 (Hardware Interface)

마우스나 키보드, CPU 등 컴퓨터에 사용되는 하드웨어들은 여러 회사에서 제작이되고 다양한 제품이 있다. 그만큼 하드웨어가 작동하기 위한 다양한 소프트웨어들이 있는데 복잡한 과정 없이 다양한 장치의 소프트웨어가 운영체제를 통해 작동할 수 있도록 만들어주는 것이 하드웨어 인터페이스이다.   
즉, 다양한 하드웨어가 별도의 설치 없이도 운영체제를 통해서 원활하게 사용될 수 있도록 만드는 장치나 기능을 의미한다.

이것 덕분에 사용자는 하드웨어가 어느 회사의 어떤 모델명인지 신경쓰지 않고 사용할 수 있다.   
하드웨어 인터페이스는 드라이버라는 소프트웨어를 통해 작동이 되는데, 자주 쓰이는 드라이버(키보드나 마우스)는 운영체제에 미리 설치가 되어있으며 드라이버가 없더라도 운영체제에서 자동으로 설치를 진행하여 사용자가 하드웨어 장치 종류를 신경쓰지 않고 사용할 수 있는 것이다. 이러한 기능을 플러그 앤드 플레이라고 한다.   
단, 일부 드라이버(프린터나 그래픽카드)들은 수동으로 설치가 필요하다.

간단히 정리하면! 하드웨어 인터페이스란 사용자가 다양한 부품을 편리하게 사용하기 위해 운영체제에서 제공하는 장치나 기능이다!

#### 사용자 인터페이스 (User Interface)

사용자가 운영체제를 편리하게 사용할 수 있도록 지원하는 기능이다.   

오래전에는 운영체제에 그래픽 유저 인터페이스(GUI)가 없어서 키보드와 줄글로 이루어진 화면만을 가지고 컴퓨터를 사용했다고 한다;   
하지만 지금은 운영체게가 GUI를 제공하면서 폴더를 키보드로 여는 것이 아니라 마우스의 더블클릭으로 간단하게 열 수 있고 터치 스크린 화면을 제공하고 있다면 단순히 화면을 터치하는 것으로도 가능하다.

#### 유틸리티 (Utility)

컴퓨터가 할 수 있는 작업이 늘어남에 따라 점점 복잡한 작업을 수행하게 되었고, 운영체제 또한 마찬가지로 점점 기능이 많아지면서 모든 작업을 수행하기 어렵게 되었다.   
이러한 운영체제를 위해서 운영체제의 작업을 보조하는 소프트웨어가 등장했는데 이를 유틸리티라고 한다. 대표적으로 바이러스 검사, 디스크 조각 모음, 압축 프로그램 등이 있다.

</br>

## 프로세스

프로세스는 프로그램의 인스턴스로 운영체제에서 가장 기본적인 작업 단위이다. 테스크(Task)라고도 불린다.   
프로그램이 디스크로부터 메모리에 적재(로드)되어 운영체제에게 주소 공간, 파일, 메모리 등을 할당받은 상태이다.   
프로세스는 최소 하나의 쓰레드(Thread)를 가진다.   

프로그램이 프로세서가 되기 위해서는 운영체제로부터 만들어지는 프로세스 제어 블록(PCB, Process Control Block)을 받아야 가능하다.   
즉, PCB가 생성되었다는 것은 어떤 프로그램이 프로세스로 전환되었다는 것을 의미하기도 한다.   
프로세스 생성에 필수적인 PCB에 관해서 설명해보겠다.

### PCB(Process Control Block)

운영체제가 프로세스들을 관리하기 위하여 사용하는 자료구조를 의미한다.

PCB가 생성되고 폐기되는 동안 일련의 과정을 단순히 하면 아래와 같다. 
1. 운영체제는 프로세스 생성과 동시에 해당 프로세스와 대응하는 고유한 PCB를 생성한다.   
2. 프로세스가 작업을 중단(혹은 보류)해야 한다면 진행 중인 작업을 PCB에 저장하고 가지고 있던 자원(CPU 등)을 반환시킨다.   
3. 이후 프로세스가 다시 작업을 시작할 때, PCB에 저장되어있던 내용을 불러와 다시 작업을 시작할 수 있도록 한다.   
4. 프로세스가 종료되면 프로세스가 메모리에서 삭제되고 PCB 또한 폐기된다.

PCB에 저장되는 정보는 아래와 같다.

+ 포인터 : 해당 프로세스 다음에 작업을 기다리는 프로세스를 가리킨다.
+ 프로세스 식별자(Process ID, PID) : 프로세스 식별자
+ 프로세스 상태 : 생성, 준비, 실행, 대기, 종료 등의 상태를 저장
+ 프로그램 카운터 : 프로세스가 다음에 실행할 명령어의 주소
+ 각종 레지스터 : 프로세스가 작업을 중단한 시점의 레지스터의 값들
  + 레지스터(register)
    프로세서에 위치한 고속 메모리로 극히 소량의 데이터나 계산 중의 중간 값울 저장하여 프로세서가 바로 사용할 수 있는 데이터를 담고 있는 영역   
+ CPU 스케쥴링 정보 : 프로세스의 작업 우선순위, 스케줄 큐에 대한 포인터 등 (아래의 CPU 스캐줄링 참고)
+ 메모리 관리 정보 : 프로세스가 할당받은 메모리 위치 정보, 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함 (아래의 메모리 관리 전략 참고)
+ 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 사용중인 파일 목록
+ 계정 정보 : 계정 번호, CPU 할당 시간, CPU 사용시간 등
+ PPID와 CPID : 부모-자식 프로세스 구분자, PPID는 parent PID를 CPID는 child PID를 의미
+ 등등..

참고로.. 운영체제도 프로그램이기 때문에 프로세스 형태로 실행되며 운영체제 관련 프로세스들은 커널 프로세스(kernel process)라고 부른다. 이러한 커널 프로세스들은 부트스트랩이라는 프로그램이 메모리에 올려주며 커널 프로세스들이 실행된 이후에 일반 프로세스가 실행된다.

### 상태 주기

프로세스는 작업 상태에 따라 보통 5가지의 상태를 가진다.   
단, 일괄작업 시스템에서는 3가지(생성, 실행, 완료), 시분할 시스템에서는 4가지(생성, 준비, 실행, 완료) 상태를 가지며, 
프로세스를 유지할 메모리가 부족할 경우 추가로 2가지의 상태를 더 가지게 된다.   

<img src="../image/1.3%20Process2.png" width="70%" height="70%">

+ 상태
  + 생성(create) : 프로그램에게 메모리를 할당하여 프로세스를 만들고 운영체제는 해당 프로세스의 PCB를 가지게 된다.
  + 준비(ready) : 프로세스가 CPU를 할당받기 위하여 기다리는 상태
  + 실행(running) : 프로세스가 타임 슬라이스와 CPU를 할당 받아서 작업을 하고있는 상태, 프로세스 간 컨텍스트 스위칭이 일어난다.
    + 타임 슬라이스 : 일정 시간
    + 컨텍스트 스위치(Context Switching)   
      실행중이던 프로세스를 PCB에 저장하고 다음 프로세스의 PCB가 CPU에 세팅되는 작업, 새로운 프로세스가 CPU를 차지하는 작업
      CPU를 차지하는 프로세스가 바뀐다면(입출력 요청, 타임아웃 등) 항상 발생한다.
  + 대기(waiting) : 입출력 요청에 대한 응답을 대기하고 있는 상태
  + 종료, 완료(terminated) : 프로세스 작업이 완료되어 프로세스가 종료되고 그것의 메모리와 대응되는 PCB가 반환된다.
  + 보류 대기 : 대기 상태에서 스와핑으로 프로세스의 메모리가 해제된 상태, 입출력이나 이벤트가 끝나면 보류 준비상태로 바뀐다.
  + 보류 준비 : 준비 상태에서 스와핑으로 프로세스의 메모리가 해제된 상태, 메모리에 여유가 다시 생기면 다시 메모리를 할당 받는다.
    + 스와핑(Swapping) : 프로세스의 일부나 전체를 메모리에서 보조기억장치로 옮겨놓는 방법
  + 디스패치(dispatch) : CPU 스케줄러에 의해 선정된 준비 상태의 프로세스가 실행되는 것 (아래의 CPU 스캐줄링 참고)
  + 인터럽트(타임아웃) : 예기치 않은 상황 혹은 타임 슬라이스 내로 수행이 완료되지 않아 현재 실행중인 프로세스을 중단하고 준비 상태로 바꾸는 것
  + 보류(suspend) : 메모리가 꽉 차서 일부 프로세스를 메모리 밖으로 내보내야 하거나 실행을 미뤄도 큰 지장이 없는 프로세스인 경우 보류 대기 상태로 바뀌는 것

### 메모리 영역

프로세스는 어떤 프로그램을 실행하느냐에 따라 다르지만 일반적으로 스택, 힙, 데이터, 코드 메모리 영역이 있다.

+ 스택(stack) 영역   
  지역변수나 함수의 매개변수와 같은 임시 데이터에 대한 메모리 할당에 관여한다.   
  함수 호출 시 생성되고 함수가 끝나면 시스템에 반환된다.   
  메모리가 높은 주소에서 낮은 주소의 방향으로 할당이 되며 런타임에 크기가 결정되는 특징이 있다.
  + 스택 오버플로우(Stack Overflow) : 스택 영역이 이용 가능한 공간 이상을 사용하려고 시도할 때 발생하는 현상
+ 힙(heap) 영역   
  동적 메모리 할당에 관여한다.   
  메모리가 낮은 주소에서 높은 주소의 방향으로 할당이 되며 런타임에 크기가 결정되는 특징이 있다.
  + 힙 오버플로우(Heap Overflow) : 힙 영역이 이용 가능한 공간 이상을 사용하려고 시도할 때 발생하는 현상
+ 데이터(data) 영역   
  프로그램의 전역 변수와 정적(static)변수가 저장되는 영역   
  데이터 영역은 프로그램의 시작과 함께 할당되며 프로그램이 종료되면 소멸한다.
+ 코드(code) 영역   
  실행할 프로그램의 코드가 저장되는 영역으로 텍스트 영역이라고도 부른다.   
  프로그램 명령이 위치하는 곳으로 기계어로 제어된다.

힙은 메모리 위쪽 주소부터 할당되고, 스택은 메모리 아래쪽 주소부터 할당되기 때문에 각 영역이 상대 공간을 침범하는 일이 발생할 수 있다.

이때 힙이 스택을 침범하는 경우를 힙 오버 플로우라 하고, 스택이 힙을 침범하는 경우를 스택 오버 플로우라고 한다.

<img src="../image/1.3%20Process1.png" width="20%" height="20%">

</br>

## 쓰레드

프로세스와 CPU의 실행 단위   
프로세스가 실행 상태가 되어 CPU를 사용할 수 있을 때, 스케줄러가 CPU에 전달하는 일 하나가 스레드이다.   
일반적으로 한 프로그램은 하나의 쓰레드를 가지고 있지만, 환경에 따라 둘 이상의 쓰레드를 동시에 실행할 수 있다.

각 쓰레드는 독립적인 작업 수행을 위해 쓰레드 ID, 프로그램 카운터, 레지스터 집합, 그리고 스택 영역을 가지며   
다른 쓰레드 간의 통신을 위해서 코드/데이터/힙 영역 그리고 공유 파일 등의 운영체제 자원들을 공유한다.

### TCB(Thread Control Block)

운영체제가 **쓰레드를 포함한 커널**을 관리하기 위한 자료구조를 의미한다.   
프로세스의 쓰레드를 관리하는 것이 아니다!   

TCB는 일반적으로 아래의 정보를 저장한다.

+ 스레드 식별자 : 모든 스레드에 할당되어있는 고유 ID(tid)
+ 스택 포인터 : 프로세스 내의 스레드의 스택
+ 프로그램 카운터 : 스레드가 이어서 실행할 명령어의 주소
+ 스레드의 상태(실행, 준비, 대기, 시작, 완료)
+ 스레드의 레지스터 값
+ 스레드가 있는 프로세스의 프로세스 제어 블록(PCB)에 대한 포인터

자세한 정보를 알기는 어려웠으나 아래의 정보는 얻을 수 있었다.   

1. 하나의 (커널) 쓰레드에 관한 정보를 가지며 PCB보다는 작은 데이터를 저장한다.   
2. TCB를 사용하면 PCB는 상태주기를 저장하지 않는다.
3. 쓰레드에는 사용자 쓰레드와 커널 쓰레드, 멀티레벨 쓰레드와 같이 다양한 종류가 있다.
4. 일반적으로 쓰레드라 함은 커널 혹은 멀티레벨 쓰레드를 의미한다.

아직 커널 정리를 못해서 커널과 인터페이스부터 정리하고 진행할 예정이다.

 참고로...   
 PCB의 다른 이름인 TCB(Task Control Block)과 줄임말이 겹친다;;

### 멀티 프로세스와 멀티 쓰레드

여러 작업을 동시에 수행하기 위한 방법은 대표적으로 멀티 프로세스와 멀티 쓰레드가 있다.
둘의 장단점이 뚜렷하니 상황에 맞는 방식을 선택하는 것이 좋다.

| -- | 멀티 프로세스 | 멀티 스레딩 | 
| -- | -- | -- |
| 의미 | 하나의 프로그램으로 여러 개의 프로세스로 만들어 각 프로세스가 병렬적으로 작업을 수행하는 방식 | 운영체제가 소프트웨어적으로 프로세스를 작은 단위의 스레드로 분할하여 운영하는 기법 |
| 장점 | 하나의 프로세스가 오류로 인하여 종료되더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다. (독립적) | 메모리 공간과 시스템 자원 소모가 줄어든다.<br>쓰레드 간의 통신은 공유 영역인 힙 영역을 이용하기 때문에 비교적 간단하며 빠르다.<br>컨텍스트 스위치가 빠르게 이루어진다. | 
| 단점 | 연산량이 많고 메모리 공간을 많이 소비한다.<br>프로세스간 통신이 스레드에 비하여 느리다.<br>컨텍스트 스위칭이 상대적으로 느리다. | 공유되는 영역인 힙 영역에 대한 동기화 작업이 필요하다.<br>오류로 인해 하나의 쓰레드가 종료되면 전체 쓰레드가 종료될 수 있다. |

> 현실에서도 알바 2명을 뽑는 것 보다는 일을 잘하는 알바 1명을 뽑고 시급을 1.5배로 주는 것이 더 효율이 좋다.   
물론 일 잘하는 알바가 몸이 아파서 빠지면 난리가 나겠지만..

멀티 태스킹

운영체제가 CPU에 작업을 줄 때, 시간을 잘게 나누어 분배하는 기법(시분할 시스템)

멀티 프로세싱

CPU 혹은 컴퓨터를 여러 개 사용하여 여러 개의 스레드를 동시에 처리하는 작업환경(병렬처리, 분산 시스템)

</br>

## 프로세스/쓰레드 동기화

멀티 프로세스/쓰레드에서 프로세스들이 동일한 자원에 동시에 접근하여 충돌이 일어나는 것을 막기 위해서   
하나의 자원(함수나 코드)을 한 순간에 하나의 프로세스(쓰레드)만이 이용하도록 제어하는 것을 의미한다.   

+ 용어
  + 동기(Synchronous) : 앞의 작업이 끝나야지만 뒤의 작업이 시작되는 작업 구조   
  + 비동기(Asynchronous) : 앞의 작업과 뒤의 작업이 동시에 시작되고 어느 작업이 먼저 끝날지 알 수 없는 작업 구조

<img src="../image/1.3%20Sync1.png">

### Critical Section(임계영역)

공유 자원(공유하는 변수나 파일 등)에 접근하는 작업을 실행하는 **코드 영역**

임계영역에서 사용하는 데이터의 동기화를 위한 기본 조건 3가지가 있다.

+ Mutual Exclusion(상호 배제)   
  프로세스 P1 이 임계영역에서 실행중이라면, 다른 프로세스들은 임계영역에서 접근할 수 없다.
+ Progress(진행)   
  임계영역에서 실행중인 프로세스가 없고, 별도의 동작이 없는 프로세스들만 임계영역 진입 후보로서 참여될 수 있다.
+ Bounded Waiting(유한 대기)   
  P1 이 Critical Section 에 진입 신청 후 부터 받아들여질 때가지, 다른 프로세스들이 Critical Section 에 진입하는 횟수는 제한이 있어야 한다.

위의 조건 중에서 상호 배제의 조건을 만족시키기 위해 다양한 방법이 제시되었다.
대표적으로 뮤텍스와 세마포어를 알아보겠다.

</br>

#### 락(Lock 혹은 Mutex, 뮤텍스)

상호 배제(Mutual Exclusion)을 줄여 뮤텍스(Mutex)라고도 부르는 동기화 방법 중 하나로,   
lock 매커니즘을 활용하여 자원의 **동시 사용을 제한하는 방법**을 의미한다.   
(lock 매커니즘의 자원에 대한 접근 제어용으로 사용되는 **변수**를 의미하기도 한다.)

lock 매커니즘이란,   
lock을 획득해야만 임계영역에 들어갈 수 있도록 제한을 걸어두고 lock을 한 프로세스만 가질 수 있도록 한 상태에서   
임계영역에 진입하는 프로세스는 lock을 획득하고 임계영역을 빠져나올 때, lock을 해제(unlock)하여   
자원에 접근하는 프로세스가 항상 1개이도록 제한하는 방법을 의미한다.

+ 한계점
  + 시간 효율성이 좋지 않아 멀티 프로세서에서는 사용하기 힘들다.

</br>

#### 세마포어(Semaphores)

signal 매커니즘을 활용하여 자원의 **접근성을 제한하는 방법**을 의미한다.   
(signal 매커니즘의 자원에 대한 접근 제어용으로 사용되는 **변수**를 의미하기도 한다.)

signal 매커니즘이란,   
변수(일반적으로 정수)를 사용하여 1개 이상의 공유 자원에 대한 접근을 제한하는 방법이다.   
세마포어(변수)를 자원의 개수로 초기화하고 자원을 사용하면 변수를 감소, 사용을 종료하면 변수를 증가시킨다.

변수의 증감에 wait과 signal이라고 불리는 함수를 사용하며,   
복수의 프로세스(쓰레드)가 동시에 여러 임계영역으로 접근이 가능하다는 특징이 있다.   
자세한 설명은 아래와 같다.

1. wait을 먼저 호출하여 임계 영역에 들어갈 수 있는지 확인한다.    
   아래는 busy waiting 문제를 해결한 wait 함수이다.
     
</br>

    S = 3 # 임계 영역에 들어갈 수 있는 쓰레드, 프로세스는 3개다.

    wait(s) {
        S--;
        if S < 0
            // 이 프로세스를 재움 큐에 추가 (잠듦)
    }

</br>

2. 조건에 만족하면, wait을 빠져나와 임계영역으로 들어가 작업을 진행한다.
3. 임계영역을 빠져나올 때, signal 이 호출하여 임계영역을 빠져나왔다는 것을 알린다.

</br>

     signal(S) {
         S++;
         if S <= 0
             // 재움 큐로부터 프로세스를 제거 (깨어남)
     }
     
</br>

+ (참고) 바쁜 대기(busy waiting 또는 spinning)   
     원하는 자원에 대한 권한을 얻을 때까지 계속 조건을 검사하는 것을 의미   
     프로세스들의 자원사용시간이 짧으면 효율적일 수 있지만 반복문을 통한 자원 효율이 떨어진다.   
     진입을 시도했지만 실패한 프로세스에 대해 Block시킨 뒤, 임계영역에 자리가 날 때 다시 깨우는 방식을 사용하여 문제점을 해결한다.

세마포어에서 사용하는 변수의 종류에 따라 카운팅 세마포어와 이진 세마포어 두 종류로 나뉜다.

+ 카운팅 세마포어(counting semaphores)   
  다수의 자원에 대한 접근 제어용으로 사용된다.   
  위에서 설명한 세마포어가 카운팅 세마포어이다.

+ 이진 세마포어(binary semaphores)   
  이름 그대로 변수에 0 과 1 값만 사용하는 세마포어이다.   
  결과적으로 조건과 과정이 뮤텍스와 같아 뮤텍스라고도 부르지만 논란이 많다.

[이해에 도움이 되는 블로그](https://worthpreading.tistory.com/90)

#### 뮤텍스 vs 세마포어

두 동기화 방식의 차이점을 구별하는 것이 중요하므로 따로 정리하려고 하였으나   
정확히 이해가 되지 않아 그나마 이해한 부분만 정리하겠다.

+ 뮤텍스는 단일 공유 자원에 대해, 세마포어는 다수 공유 자원에 대해 접근이 가능하다.
+ 뮤텍스는 lock이 되어있다/아니다 의 두 가지 상태만 표시하면 되기 때문에 바이너리 변수이지만,   
  세마포어는 정수 변수도 가질 수 있다.
+ 뮤텍스는 lock을 한 프로세스만이 unlock이 가능하다. 
  (바이너리 세마포어가 아닐 때) 세마포어가 가지고 있는 변수는 자원이 필요한 어떤 프로세스라도 변경 가능하지만 한 시점에 하나의 프로세스만 변경이 가능하다.

#### 교착상태(DeadLock)

위의 방법들은 모두 완벽한 동기화 기법이 아니므로 원하지 않는 상황이 일어나기도 하는데 그 중 하나가 교착상태이다.

두 개 이상의 작업이 서로 상대방의 작업이 끝나기 만을 기다리고 있어 결과적으로 아무것도 완료되지 못하는 상태를 의미한다.
여기서 작업이란, 동기화 작업(세마포어)이 될 수도 있고 DB 작업(트렌젝션) 등..이 될 수도 있다.

위키백과에서 재미있는 예시가 있어 함께 올려보겠다.

    먼 길

    아기가 잠드는 걸
    보고 가려고
    아빠는 머리맡에
    앉아 계시고.
    아빠가 가시는 걸
    보고 자려고
    아기는 말똥말똥
    잠을 안 자고.
    
    - 윤석중

*아..아앗..*

#### 참고

+ https://dailyheumsi.tistory.com/133?category=855210
+ https://afteracademy.com/blog/difference-between-mutex-and-semaphore-in-operating-system

</br>

## 스케줄링

작업을 수행하기 위해서 자원을 할당하는 과정이나 행동이다.    
여기서 자원은 cpu가 될 수도 있고 디스크가 될 수도 있으며 작업은 프로세스나 쓰레드가 될 수 있다.
운영체제의 스케줄러 프로세스에 의해서 관리, 진행된다.

스캐줄링을 통해서 하나의 cpu로도 멀티태스킹이 가능하게 만들며 더 효율적인 작업 진행이 이루어지도록 한다.
아래에서 서술한 것들 중 하나 이상을 충족시키는 것을 목표로 한다.

1. 처리량 최대화
2. 대기 시간 최소화 (자원을 얻기위해 대기하는 시간)
3. 응답 시간 최소화 (사용자에게 정보를 출력하기까지의 시간)
4. 공정성 극대화 (각 프로세스에 동일한 CPU 시간, 또는 각 프로세스의 우선 순위 및 작업 부하에 따라 보다 일반적으로 적절한 시간)

## 스케줄러 종류

스케줄러는 프로세스의 작업 상태에 따라 큐(Queue)를 이용해서 관리를 하는데 이 큐에는 세 가지 종류가 존재한다.

+ Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합
+ Ready Queue : 현재 메모리 내에 있으면서 CPU 를 잡아서 실행되기를 기다리는 프로세스의 집합
+ Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합

또한, 얼마나 자주 결정을 내려야 하는지에 따라   
"장기 스케줄링", "중기 스케줄링" 및 "단기 스케줄링" 세 가지 종류로 구분한다.

참고로 현재에 이르러서는 cpu가 좋아지고 가상 메모리 관리도 발달되면서 단기 스케줄러만 사용한다고 한다.   
가상 메모리 관리로 프로세스를 장기 스케줄러 쓸 필요 없이 바로바로 메모리를 할당해주면 되기 때문

### 장기스케줄러(Long-term scheduler or job scheduler)

+ 메모리와 디스크 사이의 스케줄링을 담당하여 프로세스에게 메모리를 할당(admit)하는 역할
+ 실행중인 프로세스의 수 제어
+ 프로세스의 상태 변화 : new(create) -> ready (프로세스를 Ready Queue에 이동시킴)
+ 입출력 빈도가 높은 프로세스와 cpu 작업 빈도가 높은 프로세스를 적절히 선택하여 큐에 올리는 것이 중점

### 단기스케줄러(Short-term scheduler or CPU scheduler)

+ CPU 와 메모리 사이의 스케줄링을 담당하며 **CPU 스케줄러**라고도 불린다.
+ Ready Queue 에 존재하는 프로세스 중 어떤 프로세스를 작업시킬지(running) 결정
+ 프로세스에 CPU 를 할당(scheduler dispatch)
+ 프로세스의 상태변화 : ready -> running -> waiting -> ready

### 중기스케줄러(Medium-term scheduler or Swapper)

+ 여유 공간 마련을 위해 프로세스가 가진 메모리를 해제(스와핑-Swapping)한다.
+ 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절
+ 프로세스의 상태 변화 : ready -> suspended

*****

*프로세스 상태주기*

> <img src="../image/1.3%20Process2.png" width="50%" height="50%">

##### 참고

+ https://jhnyang.tistory.com/372


### CPU 스케줄러(단기스케줄러) 종류

CPU를 사용하려고 하는 프로세스(Ready Queue 에 있는 프로세스)들 사이의 우선순위를 관리하는 스케줄러

+ CPU 스케줄링 종류
  + 비선점 프로세스 스케줄링   
    일단 CPU를 할당받으면 CPU burst가 완료될 때까지 CPU를 반환하지 않는다. 할당되었던 CPU가 반환될 때만 스케줄링이 이루어진다.
    + FCFS 스케줄링(First Come First Served Scheduling)
    + SJF 스케줄링(Shortest Job First Scheduling)
  + 선점 프로세스 스케줄링   
    현재 수행중인 프로세스의 우선순위 보다 더 큰 우선순위를 가지는 새로운 프로세스가 도착하면 CPU 를 뺏긴다.
    + SRTF 스케줄링(Shortest Remaining-Time First Scheduling)
    + RR 스케줄링(Round Robin Scheduling)

#### FCFS(First Come First Served)

CPU를 먼저 요청한 프로세스가 먼저 CPU를 배정받는 비선점 스케줄링 방법

+ 장점
  + 구현이 가장 간단하고 처리 순서가 명확하다.

+ 단점
  + Convoy Effect   
    소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상이 생길 수 있다.
  

#### SJF(Shortest Job First) & SRTF(Shortest Remaining time First)

CPU burst time(처리시간)이 짧은 프로세스에게 먼저 CPU를 할당해주는 스케줄링 방법   
비선점 스케줄러이면 SJF(Shortest Job First), 선점형 스케줄러이면 SRTF(Shortest Remaining time First)이라고 부른다.

현재 수행중인 프로세스의 남은 burst time 보다 더 짧은 CPU burst time 을 가지는 새로운 프로세스가 도착하였을 때,   
SJF는 도착하면 대기 큐 head 부분에 새로운 프로세스를 대기시키고   
SRTF는 수행중인 프로세스에게서 CPU를 빼앗아 새로운 프로세스에게 할당해준다.

+ 장점
  + 평균 대기 시간이 가장 짧게 나오는 방법이다.
  
+ 단점
  + Starvation   
    CPU 사용시간이 긴 프로세스들이 영원히 CPU 할당을 못 받는 상황이 생길 수 있다.
    + Starvation 해결방법 - Aging   
    대기하고있는 프로세스에 나이를 부여하여 처리시간이 긴 프로세스여도 기다린 시간이 길면 자원을 할당받을 수 있도록 한다.
  + (SRTF만 해당) 새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 CPU burst time(CPU 사용시간)을 측정할 수가 없다.

#### Round Robin

각 프로세스에게 같은 **할당 시간(Time Quantum)** 를 설정하여   
CPU를 점유한 프로세스가 할당 시간을 지나면 선점당하고 프로세스 대기열의 제일 뒤에 가서 다시 줄을 선도록 하는 선점 스케줄링이다.   
프로세스의 Context Switching(인터럽트 요청에 의해 기존 프로세스를 PCB에 저장하고 다음 프로세스의 상태와 레지스터 값으로 교체하는 작업) 기능이 필수적이다.

+ 장점
  + 현대적인 CPU 스케줄링
  + CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적
  + Response time(응답 시간)이 빨라진다.   
    n 개의 프로세스가 ready queue 에 있고 할당시간이 q(time quantum)인 경우   
    각 프로세스는 q 단위로 CPU 시간의 1/n 을 얻는다. 즉, 어떤 프로세스도 (n-1)q time unit 이상 기다리지 않는다.
  + 프로세스가 CPU를 사용하는 만큼 기다리는 시간도 증가한다. (꽤 공정한 스케줄링이다.)
  
+ 단점
  + 설정한 time quantum이 너무 커지면 FCFS와 다를바가 없어진다.
  + 설정한 time quantum이 너무 작으면 잦은 인터럽트 요청으로 인한 Context Switching에 과부화(Overhead)가 발생할 수 있다.

## 메모리 관리

이름 그대로 컴퓨터 메모리를 관리하는 행위이다.   
가장 단순한 형태의 메모리 관리 방법은 프로그램의 요청이 있을 때,   
메모리의 일부를 해당 프로그램에 할당하고 더 이상 필요하지 않을 때 나중에 다시 사용할 수 있도록 할당을 해제하는 것이다.   

메모리 관리의 주 목표는 다음과 같다.
+ 여러 프로세스가 동시에 실행될 수 있도록 메모리 공간을 제공할 것
+ 시스템 사용자들을 위해 만족할 만한 수준의 성능을 제공할 것
+ 각 프로그램의 리소스를 보호할 것
+ 프로세스 사이에 있는 메모리 공간을 공유할 것
+ 프로그래머를 위해 되도록 메모리 공간의 어드레싱을 투명하게 할 것

### 메모리 관리 배경

각각의 프로세스는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다.   
하지만 프로세스를 관리하는 운영체제는 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않으며   
여러가지 기법을 통해서 프로세스에 할당된 메모리를 관리한다.

아래와 같은 용어들을 먼저 숙지하고 메모리 관리 방법을 확인하자.

+ 스와핑(Swapping)   
  프로세스에 할당할 메모리의 관리를 위해 사용되는 기법으로   
  CPU 할당 시간이 끝난 프로세스의 메모리를 보조기억장치(e.g. 하드디스크)로 내보내어 메모리 공간을 확보하는 방법이다.
  + swap-in : 보조기억장치에서 주기억장치(RAM)으로 불러오는 과정
  + swap-out : 주기억장치에서 보조기억장치로 내보내는 과정
+ 단편화 (Fragmentation)
  프로세스들이 메모리에 적재되고 제거되는 일이 반복되면서 여유 메모리들이 비연속적이고 파편화 되어있는 경우를 의미한다.    
  단편화로 인해 나뉘어진 메모리의 총 크기는 충분히 크지만 실재로 할당(사용)이 불가능하여 메모리 효율성을 떨어뜨리는 문제를 야기한다.   
  단편화는 2 가지 종류로 나뉜다.
  + 외부 단편화: 여유 메모리는 충분한데 실재로 프로세스를 할당할 수 없는 경우
  + 내부 단편화: 메모리를 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어 메모리 공간이 낭비 되는 상황
  + 압축(defragmentation) : 외부 단편화를 해소하기 위해 프로세스가 사용하는 공간들을 한쪽으로 몰아 자유공간을 확보하는 방법론, 속도가 느리다..

#### 압축에 대한 [예시](https://en.wikipedia.org/wiki/File_system_fragmentation)

압축 전
| `Process A` | free | `Process B` | free | `Process C` | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; free &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; | `Process D` |
| ----------- | ---- | ----------- | ---- | ----------- | :--------------------------------------------------------------------------------------: | ----------- |

압축 후
| `Process A` | `Process B` | `Process C` | `Process D` | &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; free &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; |
| ----------- | ----------- | ----------- | :---------: | ------------------------------------------------------------------------------------------------------------------ |

Swapping으로 프로세스에 메모리를 할당/해제하면서 메모리 관리를 하다가   
생기는 문제점들(메모리 단편화 문제)을 해결하기 위하여 아래와 같은 기법을 사용하기 시작하였다.

### 메모리 단편화 해결 방법

+ 용어
  + 페이지(Page) : 논리메모리(프로세스가 가진 메모리)를 일정 크기의 블록으로 나눈 것
  + 프레임(Frame) : 물리메모리(RAM이 가진 메모리)를 페이지와 같은 크기로 나눈 것
  + 페이징 테이블(Pging Table) : 페이지와 프레임을 대응시켜주는 테이블
  + 세그먼트(Segment) : 메모리를 기능 혹은 의미를 기준으로 나눈 것   
    하나의 프로세스를 구성하는 주소 공간을 일반적으로 코드, 스택, 데이터로 나눈 것도 의미 단위로 나눈 것이라 볼 수 있다.

### Paging(페이징)

하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 해소하기 위한 등장한 메모리 관리 방법으로   
페이지를 프레임에 넣어 나뉘어진 메모리 공간을 모두 활용할 수 있도록 하는 기법이다.

각 페이지는 **순서에 상관없이** 프레임에 저장되기 때문에   
페이지와 프레임을 대응시키기 위해 페이지 매핑(page mapping) 과정이 필요하며 페이징 테이블(paging table)을 통해서 매핑이 된다.

+ 장점
  + 연속적이지 않은 공간도 활용할 수 있기 때문에 외부 단편화 문제를 해결

+ 단점 
  + 내부 단편화 문제 존재   
    예를들어 페이지 크기가 1,024B 이고 **프로세스 A** 가 3,172B 의 메모리를 요구한다면   
    3 개의 페이지 프레임(1,024 \* 3 = 3,072) 하고도 100B 가 남기때문에 총 4 개의 페이지 프레임이 필요하다.   
    결론적으로 4 번째 페이지 프레임에는 924B(1,024 - 100)의 여유 공간이 남게 되어 내부 단편화 문제가 발생한다.

#### 페이징 테이블 예시 사진

<img src="../image/1.3%20Paging.PNG" width="50%" height="50%">

#### 페이지 단위 조정

페이지 단위를 작게하면 내부 단편화 문제도 해결할 수가 있으나, 대신 페이지 매핑 과정이 많아지므로 오히려 효율이 떨어질 수 있다.   
반대로 단위를 크게 하면 내부 단편화 문제가 심화되고 페이지 매핑 과정이 적어지므로 적절한 단위를 설정해야 한다.

### Segmentation(세그멘테이션)

페이징과 비슷한 방식으로 진행되지만, 메모리를 세그먼트로 나누어 활용하는 기법이다.

세그먼트 또한 페이징과 같이 세그먼트 테이블(segment table)을 사용하여 매핑을 한다.   
세그먼트 테이블에는 각 세그먼트의 물리 주소와 길이를 저장되며 이 테이블을 통해서 매핑이 된다.

+ 장점
  + 프로세스가 필요한 메모리 만큼 나누어 할당해주기 때문에 내부단편화 문제가 해결된다.
  + 의미상으로 나뉘는 세그먼트 특징으로 인하여 공유와 보안의 측면에서 페이징 기법에 비해 훨씬 효과적이다.

+ 단점 
  + 크기가 일정하지 않은 세그먼트 특징으로 인하여 외부 단편화 문제는 그대로 남는다.
  + 테이블에 사용되는 메모리가 페이징에 비해 더 크다. 

##### 참고

+ (기본기를 쌓는 정아마추어 코딩블로그)[https://jeong-pro.tistory.com/91]
+ https://jhnyang.tistory.com/290
