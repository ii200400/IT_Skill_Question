# 1-3. 컴퓨터 구조와 운영체제

+ OS 개요
+ 프로세스와 쓰레드
  + 프로세스
  + 쓰레드
  + 멀티 프로세스와 멀티 쓰레드
+ 프로세스/쓰레드 동기화
  + 임계영역
+ 스캐줄러
+ CPU 스캐줄링
+ 메모리 관리 전략
+ 가상 메모리

</br>

## OS란?

사용자에게 편리한 인터페이스 환경을 제공하고, 컴퓨터 시스템의 자원을 효율적으로 관리하는 시스템 소프트웨어   
사용자와 하드웨어 사이에서 중재자 역할을 한다.   
대표적으로 마이크로소프트 윈도우, 맥 OS, 리눅스가 있다.

컴퓨터 시스템 하드웨어 및 소프트웨어 자원을 여러 사용자에게 효율적 할당, 관리, 보호하며   
제어 프로그램으로서 사용자 프로그램의 오류나 잘못된 자원 사용을 감시하고   
입출력 장치 등의 자원에 대한 연산과 제어를 관리한다.

</br>

## 프로세스와 쓰레드

### 프로세스

프로세스는 프로그램의 인스턴스로 운영체제에서 가장 기본적인 실행 단위이다.   
프로그램이 디스크로부터 메모리에 적재(로드)되어 운영체제에게 주소 공간, 파일, 메모리 등을 할당받은 상태이다.

프로세스는 메모리와 일정한 상태 주기를 가지는데 다음과 같다.

#### 메모리 영역

프로세스는 어떤 프로그램을 실행하느냐에 따라 다르지만   
대표적으로 스택, 힙, 데이터, 코드 메모리 영역이 있다.

+ 스택(stack) 영역   
  지역변수나 함수의 매개변수와 같은 임시 데이터에 대한 메모리를 할당에 관여한다.   
  함수 호출 시 생성되고 함수가 끝나면 시스템에 반환된다.   
  메모리가 높은 주소에서 낮은 주소의 방향으로 할당이 되며 프로세스가 메모리에 로드 될 때 크기가 결정된다.
  + 스택 오버플로우(Stack Overflow) : 스택 영역이 이용 가능한 공간 이상을 사용하려고 시도할 때 발생하는 현상
+ 힙(heap) 영역   
  동적 메모리 할당에 관여한다.   
  메모리가 낮은 주소에서 높은 주소의 방향으로 할당이되며 런타임에 크기가 결정되는 특징이 있다.
  + 힙 오버플로우(Heap Overflow) : 힙 영역이 이용 가능한 공간 이상을 사용하려고 시도할 때 발생하는 현상
+ 데이터(data) 영역   
  프로그램의 전역 변수와 정적(static)변수가 저장되는 영역   
  데이터 영역은 프로그램의 시작과 함께 할당되며 프로그램이 종료되면 소멸한다.
+ 코드(code) 영역   
  실행할 프로그램의 코드가 저장되는 영역으로 텍스트(code) 영역이라고도 부른다.   
  프로그램 명령이 위치하는 곳으로 기계어로 제어된다.

힙은 메모리 위쪽 주소부터 할당되고, 스택은 메모리 아래쪽 주소부터 할당되기 때문에 각 영역이 상대 공간을 침범하는 일이 발생할 수 있다.

이때 힙이 스택을 침범하는 경우를 힙 오버 플로우라 하고, 스택이 힙을 침범하는 경우를 스택 오버 플로우라고 한다.

<img src="../image/1.3%20Process1.png" width="20%" height="20%">

##### 참고

static은 Kotlin에서 const로 표기한다.

+ https://itwiki.kr/w/%EB%A9%94%EB%AA%A8%EB%A6%AC_%EC%98%81%EC%97%AD

#### 상태 주기

프로세스는 보통 5가지의 상태를 가진다.   
(프로세스를 유지할 메모리가 부족할 경우 추가로 2가지의 상태를 더 가지게 된다.)   

<img src="../image/1.3%20Process2.png" width="70%" height="70%">

+ 용어
  + 생성(create) : 프로세스가 메모리를 가지고 운영체제는 해당 프로세스의 PCB를 가지게 된다. (아래의 PCB 참고)
  + 준비(ready) : 프로세스가 CPU를 할당받기 위하여 기다리는 상태
  + 실행(running) : 프로세스가 CPU를 할당 받아서 작업을 하고있는 상태
  + 대기(waiting) : 입출력 혹은 이벤트로 인해 대기하고 있는 상태
  + 종료(terminated) : 프로그램이 종료되어 프로세스의 메모리와 대응되는 PCB가 반환된다. (그림에서는 완료라고 쓰여있다.)
  + 보류 대기 : 대기 상태에서 스와핑으로 프로세스의 메모리가 해제된 상태, 입출력이나 이벤트가 끝나면 보류 준비상태로 바뀐다.
  + 보류 준비 : 스와핑으로 프로세스의 메모리가 해제된 상태, 메모리에 여유가 다시 생기면 다시 메모리를 할당 받는다.
    + 스와핑(Swapping) : 프로세스의 일부나 전체를 메모리에서 보조기억장치로 옮겨놓는 방법
  + 디스패치 : CPU 스케줄러에 의해 선정된 프로세스가 실행되는 것 (아래의 CPU 스캐줄링 참고)
  + 인터럽트 : 예기치 않은 상황이 발생하여 현재 실행중인 작업을 즉시 중단하고 준비 상태로 바꾸는 것   
    CPU는 이후 문제 상황을 우선 처리한 후 다시 실행중이던 작업을 불러 처리한다.
  + 타임아웃 : 주어진 시간 내로 수행이 완료되지 않아서 프로세스를 준비 상태로 되돌리는 것

#### PCB(Process Control Block)

프로세스가 각자 메모리를 가지는 것 처럼   
운영체제도 프로세스들을 관리하기 위하여 PCB라는 별도의 자료구조를 가진다.

운영체제는 프로세스 생성과 동시에 해당 프로세스와 대응하는 고유한 PCB를 생성한다.   
프로세스가 작업을 중단(보류)해야 한다면 진행 중인 작업을 저장하고 가지고 있던 자원을 반환시킨다.   
PCB는 해당 프로세스의 작업을 저장한다.   
이후 프로세스가 다시 작업을 시작할 때, PCB에 저장되어있던 내용을 불러와 다시 작업을 시작할 수 있도록 한다.

PCB에 저장되는 정보는 아래와 같다.

+ 프로세스 식별자(Process ID, PID) : 프로세스 식별번호
+ 프로세스 상태 : 생성, 준비, 실행, 대기, 종료 등의 상태를 저장
+ 프로그램 카운터 : 프로세스가 다음에 실행할 명령어의 주소
+ CPU 레지스터
+ CPU 스케쥴링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등 (아래의 CPU 스캐줄링 참고)
+ 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함 (아래의 메모리 관리 전략 참고)
+ 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
+ 어카운팅 정보 : 사용된 CPU 시간, 시간제한, 계정번호 등

+ 용어
  + 레지스터(register)
    프로세서에 위치한 고속 메모리로 극히 소량의 데이터나 계산 중의 중간 값울 저장하여 프로세서가 바로 사용할 수 있는 데이터를 담고 있는 영역   
    컴퓨터 구조에 따라 크기와 종류가 다양하다.

</br>

### 쓰레드

프로세스의 실행 단위
일반적으로 한 프로그램은 하나의 쓰레드를 가지고 있지만, 환경에 따라 둘 이상의 쓰레드를 동시에 실행할 수 있다.

각 쓰레드는 독립적인 작업 수행을 위해 쓰레드 ID, 프로그램 카운터, 레지스터 집합, 그리고 스택 영역을 가지며   
다른 쓰레드 간의 통신을 위해서 코드/데이터/힙 영역 그리고 공유 파일 등의 운영체제 자원들을 공유한다.

### 멀티 프로세스와 멀티 쓰레드

#### 멀티 프로세스

똑같은 프로세스를 여러 개 만들어 한번에 여러 작업을 수행할 수 있도록 하는 것   
분신술을 사용하여 같은 사람을 여러 명 만드는 것과 비슷하다.

+ 장점
  + 하나의 프로세스가 오류로 인하여 종료되더라도 다른 프로세스에는 영향을 끼치지 않고 정상적으로 수행된다.
  
+ 단점
  + 연산량이 많고 메모리 공간을 많이 소비한다.
  + 프로세스간 통신이 스레드에 비하여 느리다.
  + 컨텍스트 스위치가 상대적으로 느리다.
    + 컨텍스트 스위치(Context Switch)   
      인터럽트 요청에 의해 기존 프로세스를 PCB에 저장하고 다음 프로세스의 상태와 레지스터 값으로 교체하는 작업

#### 멀티 스레딩

하나의 프로세스를 여러 실행 단위로 나누어 여러 쓰레드가 나눠 맡아 한번에 여러 작업을 수행하는 것   
마치 음악을 들으면서 친구와 이야기하는 것과 같다.

+ 장점
  + 메모리 공간과 시스템 자원 소모가 줄어든다.
  + 쓰레드 간의 통신은 공유 영역인 힙 영역을 이용하기 때문에 비교적 간단하며 빠르다.
  + 컨텍스트 스위치가 빠르게 이루어진다.
  
+ 단점
  + 공유되는 영역인 힙 영역에 대한 동기화 작업이 필요하다.
  + 오류로 인해 하나의 쓰레드가 종료되면 전체 쓰레드가 종료될 수 있다.

</br>

> 현실에서도 알바 2명을 뽑는 것 보다는 일을 잘하는 알바 1명을 뽑고 시급을 1.5배로 주는 것이 더 효율이 좋다.   
물론 일 잘하는 알바가 몸이 아파서 빠지면 난리가 나겠지만..

</br>

## 프로세스/쓰레드 동기화

멀티 프로세스/쓰레드에서 프로세스들이 동일한 자원에 동시에 접근하여 충돌이 일어나는 것을 막기 위해서   
하나의 자원(함수나 코드)을 한 순간에 하나의 프로세스(쓰레드)만이 이용하도록 제어하는 것을 의미한다.   

+ 용어
  + 동기(Synchronous) : 앞의 작업이 끝나야지만 뒤의 작업이 시작되는 작업 구조   
  + 비동기(Asynchronous) : 앞의 작업과 뒤의 작업이 동시에 시작되고 어느 작업이 먼저 끝날지 알 수 없는 작업 구조

<img src="../image/1.3%20Sync1.png">

### Critical Section(임계영역)

공유 자원(공유하는 변수나 파일 등)에 접근하는 작업을 실행하는 **코드 영역**

임계영역에서 사용하는 데이터의 동기화를 위한 기본 조건 3가지가 있다.

+ Mutual Exclusion(상호 배제)   
  프로세스 P1 이 임계영역에서 실행중이라면, 다른 프로세스들은 임계영역에서 접근할 수 없다.
+ Progress(진행)   
  임계영역에서 실행중인 프로세스가 없고, 별도의 동작이 없는 프로세스들만 임계영역 진입 후보로서 참여될 수 있다.
+ Bounded Waiting(유한 대기)   
  P1 이 Critical Section 에 진입 신청 후 부터 받아들여질 때가지, 다른 프로세스들이 Critical Section 에 진입하는 횟수는 제한이 있어야 한다.

위의 조건 중에서 상호 배제의 조건을 만족시키기 위해 다양한 방법이 제시되었다.
대표적으로 뮤텍스와 세마포어를 알아보겠다.

</br>

#### 락(Lock 혹은 Mutex, 뮤텍스)

상호 배제(Mutual Exclusion)을 줄여 뮤텍스(Mutex)라고도 부르는 동기화 방법 중 하나로,   
lock 매커니즘을 활용하여 자원의 **동시 사용을 제한하는 방법**을 의미한다.   
(lock 매커니즘의 자원에 대한 접근 제어용으로 사용되는 **변수**를 의미하기도 한다.)

lock 매커니즘이란,   
lock을 획득해야만 임계영역에 들어갈 수 있도록 제한을 걸어두고 lock을 한 프로세스만 가질 수 있도록 한 상태에서   
임계영역에 진입하는 프로세스는 lock을 획득하고 임계영역을 빠져나올 때, lock을 해제(unlock)하여   
자원에 접근하는 프로세스가 항상 1개이도록 제한하는 방법을 의미한다.

+ 한계점
  + 시간 효율성이 좋지 않아 멀티 프로세서에서는 사용하기 힘들다.

</br>

#### 세마포어(Semaphores)

signal 매커니즘을 활용하여 자원의 **접근성을 제한하는 방법**을 의미한다.   
(signal 매커니즘의 자원에 대한 접근 제어용으로 사용되는 **변수**를 의미하기도 한다.)

signal 매커니즘이란,   
변수(일반적으로 정수)를 사용하여 1개 이상의 공유 자원에 대한 접근을 제한하는 방법이다.   
세마포어(변수)를 자원의 개수로 초기화하고 자원을 사용하면 변수를 감소, 사용을 종료하면 변수를 증가시킨다.

변수의 증감에 wait과 signal이라고 불리는 함수를 사용하며,   
복수의 프로세스(쓰레드)가 동시에 여러 임계영역으로 접근이 가능하다는 특징이 있다.   
자세한 설명은 아래와 같다.

1. wait을 먼저 호출하여 임계 영역에 들어갈 수 있는지 확인한다.    
   아래는 busy waiting 문제를 해결한 wait 함수이다.
     
</br>

    S = 3 # 임계 영역에 들어갈 수 있는 쓰레드, 프로세스는 3개다.

    wait(s) {
        S--;
        if S < 0
            // 이 프로세스를 재움 큐에 추가 (잠듦)
    }

</br>

2. 조건에 만족하면, wait을 빠져나와 임계영역으로 들어가 작업을 진행한다.
3. 임계영역을 빠져나올 때, signal 이 호출하여 임계영역을 빠져나왔다는 것을 알린다.

</br>

     signal(S) {
         S++;
         if S <= 0
             // 재움 큐로부터 프로세스를 제거 (깨어남)
     }
     
</br>

+ (참고) 바쁜 대기(busy waiting 또는 spinning)   
     원하는 자원에 대한 권한을 얻을 때까지 계속 조건을 검사하는 것을 의미   
     프로세스들의 자원사용시간이 짧으면 효율적일 수 있지만 반복문을 통한 자원 효율이 떨어진다.   
     진입을 시도했지만 실패한 프로세스에 대해 Block시킨 뒤, 임계영역에 자리가 날 때 다시 깨우는 방식을 사용하여 문제점을 해결한다.

세마포어에서 사용하는 변수의 종류에 따라 카운팅 세마포어와 이진 세마포어 두 종류로 나뉜다.

+ 카운팅 세마포어(counting semaphores)   
  다수의 자원에 대한 접근 제어용으로 사용된다.   
  위에서 설명한 세마포어가 카운팅 세마포어이다.

+ 이진 세마포어(binary semaphores)   
  이름 그대로 변수에 0 과 1 값만 사용하는 세마포어이다.   
  결과적으로 조건과 과정이 뮤텍스와 같아 뮤텍스라고도 부르지만 논란이 많다.

[이해에 도움이 되는 블로그](https://worthpreading.tistory.com/90)

#### 뮤텍스 vs 세마포어

두 동기화 방식의 차이점을 구별하는 것이 중요하므로 따로 정리하려고 하였으나   
정확히 이해가 되지 않아 그나마 이해한 부분만 정리하겠다.

+ 뮤텍스는 단일 공유 자원에 대해, 세마포어는 다수 공유 자원에 대해 접근이 가능하다.
+ 뮤텍스는 lock이 되어있다/아니다 의 두 가지 상태만 표시하면 되기 때문에 바이너리 변수이지만,   
  세마포어는 정수 변수도 가질 수 있다.
+ 뮤텍스는 lock을 한 프로세스만이 unlock이 가능하다. 
  (바이너리 세마포어가 아닐 때) 세마포어가 가지고 있는 변수는 자원이 필요한 어떤 프로세스라도 변경 가능하지만 한 시점에 하나의 프로세스만 변경이 가능하다.

#### 교착상태(DeadLock)

위의 방법들은 모두 완벽한 동기화 기법이 아니므로 원하지 않는 상황이 일어나기도 하는데 그 중 하나가 교착상태이다.

두 개 이상의 작업이 서로 상대방의 작업이 끝나기 만을 기다리고 있어 결과적으로 아무것도 완료되지 못하는 상태를 의미한다.
여기서 작업이란, 동기화 작업(세마포어)이 될 수도 있고 DB 작업(트렌젝션) 등..이 될 수도 있다.

위키백과에서 재미있는 예시가 있어 함께 올려보겠다.

    먼 길

    아기가 잠드는 걸
    보고 가려고
    아빠는 머리맡에
    앉아 계시고.
    아빠가 가시는 걸
    보고 자려고
    아기는 말똥말똥
    잠을 안 자고.
    
    - 윤석중

*아..아앗..*

#### 참고

+ https://dailyheumsi.tistory.com/133?category=855210
+ https://afteracademy.com/blog/difference-between-mutex-and-semaphore-in-operating-system

</br>

## 스캐줄러

작업을 수행하기 위해서 자원을 할당하는 과정이나 행동   
여기서 자원은 cpu가 될 수도 있고 디스크가 될 수도 있으며 작업은 프로세스나 쓰레드가 될 수 있다.

## CPU 스케줄링

cpu 스케줄링은 다중 프로그래밍(CPU작업과 입출력 작업을 병행하는 것)을 가능하게 하는 운영 체제의 동작 기법이다.   
즉, 운영체제가 어떤 자원을 어떤 프로세스들에게 할당할지 결정하는 것을 의미한다.

그 중에서도 CPU를 사용하려고 하는 프로세스들 사이의 우선순위를 관리하는 스케줄링을 CPU스케줄링이라고 한다.

+ CPU 스케줄링 종류
  + 비선점 프로세스 스케줄링 : 프로세스가 CPU를 할당받으면 자발적으로 중지될 때까지 계속 실행되도록 보장한다.
    + FCFS 스케줄링(First Come First Served Scheduling)
    + SJF 스케줄링(Shortest Job First Scheduling)
  + 선점 프로세스 스케줄링 : 프로세스가 CPU를 할당받아 실행 중인 프로세스를 중지하고 CPU를 강제로 점유할 수 있다.
    + SRTF 스케줄링(Shortest Remaining-Time First Scheduling)
    + RR 스케줄링(Round Robin Scheduling)

### FCFS(First Come First Served)

CPU를 먼저 요청한 프로세스가 먼저 CPU를 배정받는 비선점 스케줄링 방법

+ 장점
  + 구현이 가장 간단하고 처리 순서가 명확하다.

+ 단점
  + Convoy Effect(소요시간이 긴 프로세스가 먼저 도달하여 효율성을 낮추는 현상)가 생길 수 있다. 
  

### SJF(Shortest Job First) & SRTF(Shortest Remaining time First)
다른 프로세스가 먼저 도착했어도 CPU burst time(처리시간)이 짧은 프로세스에게 먼저 CPU를 할당해주는 스케줄링 방법\
비선점 스케줄러이면 SJF(Shortest Job First), 선점형 스케줄러이면 SRTF(Shortest Remaining time First)이라고 부른다.

현재 수행중인 프로세스의 남은 burst time 보다 더 짧은 CPU burst time 을 가지는 새로운 프로세스가 도착하면\
SJF는 도착하면 대기 큐 head 부분에 새로운 프로세스를 대기시키고\
SRTF는 수행중인 프로세스에게서 CPU를 빼앗아 새로운 프로세스에게 할당해준다.

+ 장점
  + 평균 대기 시간이 가장 짧게 나오는 방법이다.
  
+ 단점
  + Starvation(CPU 사용시간이 긴 프로세스들이 영원히 CPU 할당을 못 받는 상황)이 생길 수 있다.
    + Starvation 해결방법 - Aging\
    대기하고있는 프로세스에 나이를 부여하여 처리시간이 긴 프로세스여도 기다린 시간이 길면 자원을 할당받을 수 있도록 한다.
  + (SRTF만 해당) 새로운 프로세스가 도달할 때마다 스케줄링을 다시하기 때문에 CPU burst time(CPU 사용시간)을 측정할 수가 없다.

### Round Robin
각 프로세스에게 같은 할당 시간(Time Quantum)를 설정하여\
CPU를 점유한 프로세스가 할당 시간을 지나면 선점당하고 프로세스 대기열의 제일 뒤에 가서 다시 줄을 선도록 하는 선점 스케줄링이다.

+ 장점
  + CPU 사용시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적
  + Response time(응답 시간)이 빨라진다.
  + 프로세스가 CPU를 사용하는 만큼 기다리는 시간도 증가한다. (꽤 공정한 스케줄링이다.)
  
+ 단점
  + 설정한 time quantum이 너무 커지면 FCFS와 다를바가 없어진다.
  + 설정한 time quantum이 너무 작으면 잦은 인터럽트 요청으로 인한 Context Switching에 과부화(Overhead)가 발생할 수 있다.
    + 컨텍스트 스위치(Context Switch) : 인터럽트 요청에 의해 기존 프로세스를 PCB에 저장하고 다음 프로세스의 상태와 레지스터 값으로 교체하는 작업

